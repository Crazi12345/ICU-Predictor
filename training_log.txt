2025-12-18 19:10:40,064 - INFO - Using device: cuda
2025-12-18 19:10:40,475 - INFO - Dataset downloaded to: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2
2025-12-18 19:10:40,475 - INFO - ✓ Found dataset at: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2/Dataset.csv
2025-12-18 19:10:41,729 - INFO - ✓ Loaded Dataset: 1552210 rows, 44 columns
2025-12-18 19:10:41,776 - INFO - Shape: (1552210, 43)
2025-12-18 19:10:41,864 - INFO - ✓ Features: 41, Label: SepsisLabel
2025-12-18 19:10:41,864 - INFO - ⏳ Imputing missing values per-patient...
2025-12-18 19:11:46,324 - INFO - Using device: cuda
2025-12-18 19:11:46,708 - INFO - Dataset downloaded to: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2
2025-12-18 19:11:46,708 - INFO - ✓ Found dataset at: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2/Dataset.csv
2025-12-18 19:11:47,947 - INFO - ✓ Loaded Dataset: 1552210 rows, 44 columns
2025-12-18 19:11:47,994 - INFO - Shape: (1552210, 43)
2025-12-18 19:11:48,083 - INFO - ✓ Features: 41, Label: SepsisLabel
2025-12-18 19:11:48,084 - INFO - ⏳ Imputing missing values per-patient...
2025-12-18 19:12:32,367 - INFO - Using device: cuda
2025-12-18 19:12:32,787 - INFO - Dataset downloaded to: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2
2025-12-18 19:12:32,787 - INFO - ✓ Found dataset at: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2/Dataset.csv
2025-12-18 19:12:34,014 - INFO - ✓ Loaded Dataset: 1552210 rows, 44 columns
2025-12-18 19:12:34,061 - INFO - Shape: (1552210, 43)
2025-12-18 19:12:34,150 - INFO - ✓ Features: 41, Label: SepsisLabel
2025-12-18 19:12:34,150 - INFO - ⏳ Imputing missing values per-patient...
2025-12-18 19:13:31,699 - INFO - Using device: cuda
2025-12-18 19:13:32,078 - INFO - Dataset downloaded to: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2
2025-12-18 19:13:32,078 - INFO - ✓ Found dataset at: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2/Dataset.csv
2025-12-18 19:13:33,321 - INFO - ✓ Loaded Dataset: 1552210 rows, 44 columns
2025-12-18 19:13:33,367 - INFO - Shape: (1552210, 43)
2025-12-18 19:13:33,455 - INFO - ✓ Features: 41, Label: SepsisLabel
2025-12-18 19:13:33,456 - INFO - ⏳ Imputing missing values per-patient...
2025-12-18 19:14:39,502 - INFO - Using device: cuda
2025-12-18 19:14:39,898 - INFO - Dataset downloaded to: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2
2025-12-18 19:14:39,898 - INFO - ✓ Found dataset at: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2/Dataset.csv
2025-12-18 19:14:41,118 - INFO - ✓ Loaded Dataset: 1552210 rows, 44 columns
2025-12-18 19:14:41,165 - INFO - Shape: (1552210, 43)
2025-12-18 19:14:41,254 - INFO - ✓ Features: 41, Label: SepsisLabel
2025-12-18 19:14:41,254 - INFO - ⏳ Imputing missing values per-patient...
2025-12-18 19:16:06,219 - INFO - Using device: cuda
2025-12-18 19:16:06,653 - INFO - Dataset downloaded to: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2
2025-12-18 19:16:06,653 - INFO - ✓ Found dataset at: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2/Dataset.csv
2025-12-18 19:16:07,909 - INFO - ✓ Loaded Dataset: 1552210 rows, 44 columns
2025-12-18 19:16:07,955 - INFO - Shape: (1552210, 43)
2025-12-18 19:16:08,044 - INFO - ✓ Features: 41, Label: SepsisLabel
2025-12-18 19:16:08,044 - INFO - ⏳ Imputing missing values per-patient...
2025-12-18 19:18:52,601 - INFO - ✓ Imputation complete. NaNs remaining: 0
2025-12-18 19:18:52,601 - INFO - ⏳ Scaling features per-patient...
2025-12-18 20:21:28,453 - INFO - ✓ Scaling complete.
2025-12-18 20:21:28,465 - INFO - ⚠️ Performance Optimization: Reducing dataset from 40336 to 40336 patients (50%)
2025-12-18 20:49:45,515 - INFO - Sequence data created: X_seq (40336, 256, 41), y_seq (40336, 256)
2025-12-18 20:49:46,238 - INFO - Train: torch.Size([32268, 256, 41]), Val: torch.Size([4033, 256, 41]), Test: torch.Size([4035, 256, 41])
2025-12-18 20:49:46,238 - INFO - === TWO-STAGE HYPERPARAMETER TUNING (PYTORCH) ===

2025-12-18 20:49:46,238 - INFO - STAGE 1: Fast model-family selection

2025-12-18 20:49:46,238 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-18 20:49:47,774 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-18 20:49:47,868 - INFO -   score=0.0000
2025-12-19 08:34:42,296 - INFO - Using device: cuda
2025-12-19 08:34:42,795 - INFO - Dataset downloaded to: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2
2025-12-19 08:34:42,795 - INFO - ✓ Found dataset at: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2/Dataset.csv
2025-12-19 08:34:44,029 - INFO - ✓ Loaded Dataset: 1552210 rows, 44 columns
2025-12-19 08:34:44,075 - INFO - Shape: (1552210, 43)
2025-12-19 08:34:44,165 - INFO - ✓ Features: 41, Label: SepsisLabel
2025-12-19 08:34:44,165 - INFO - ⏳ Imputing missing values per-patient...
2025-12-19 08:37:50,542 - INFO - ✓ Imputation complete. NaNs remaining: 0
2025-12-19 08:37:50,542 - INFO - ⏳ Scaling features per-patient...
2025-12-19 09:47:55,504 - INFO - ✓ Scaling complete.
2025-12-19 09:47:55,516 - INFO - ⚠️ Performance Optimization: Reducing dataset from 40336 to 40336 patients (50%)
2025-12-19 10:19:41,755 - INFO - Sequence data created: X_seq (40336, 256, 41), y_seq (40336, 256)
2025-12-19 10:19:42,217 - INFO - Train: torch.Size([32268, 256, 41]), Val: torch.Size([4033, 256, 41]), Test: torch.Size([4035, 256, 41])
2025-12-19 10:19:42,217 - INFO - === TWO-STAGE HYPERPARAMETER TUNING (PYTORCH) ===

2025-12-19 10:19:42,217 - INFO - STAGE 1: Fast model-family selection

2025-12-19 10:19:42,218 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:19:44,130 - INFO -   score=0.9333
2025-12-19 10:19:44,132 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 10:19:45,583 - INFO -   score=0.8945
2025-12-19 10:19:45,585 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 10:19:47,264 - INFO -   score=0.9198
2025-12-19 10:19:47,266 - INFO - 
✓ Stage-1 winner: RNN (score=0.9333)

2025-12-19 10:19:47,266 - INFO - STAGE 2: Exhaustive search for winner

2025-12-19 10:19:47,267 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:19:51,043 - INFO -   score=0.9875
2025-12-19 10:19:51,043 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:19:54,852 - INFO -   score=0.9862
2025-12-19 10:19:54,852 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:19:58,637 - INFO -   score=0.9472
2025-12-19 10:19:58,637 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:02,517 - INFO -   score=0.9652
2025-12-19 10:20:02,517 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:06,366 - INFO -   score=0.9240
2025-12-19 10:20:06,366 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:10,155 - INFO -   score=0.9099
2025-12-19 10:20:10,156 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:13,925 - INFO -   score=0.9581
2025-12-19 10:20:13,925 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:17,776 - INFO -   score=0.9568
2025-12-19 10:20:17,776 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:21,745 - INFO -   score=0.9165
2025-12-19 10:20:21,745 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:25,709 - INFO -   score=0.9210
2025-12-19 10:20:25,709 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:29,676 - INFO -   score=0.9437
2025-12-19 10:20:29,676 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:33,618 - INFO -   score=0.9444
2025-12-19 10:20:33,618 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:33,966 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,065 - INFO -   score=0.0000
2025-12-19 10:20:34,065 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,066 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,067 - INFO -   score=0.0000
2025-12-19 10:20:34,067 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,067 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,067 - INFO -   score=0.0000
2025-12-19 10:20:34,067 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,068 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,068 - INFO -   score=0.0000
2025-12-19 10:20:34,068 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,069 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,069 - INFO -   score=0.0000
2025-12-19 10:20:34,069 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,069 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,069 - INFO -   score=0.0000
2025-12-19 10:20:34,069 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,069 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,069 - INFO -   score=0.0000
2025-12-19 10:20:34,069 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,070 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,070 - INFO -   score=0.0000
2025-12-19 10:20:34,070 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,070 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,070 - INFO -   score=0.0000
2025-12-19 10:20:34,070 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,071 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,071 - INFO -   score=0.0000
2025-12-19 10:20:34,071 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,071 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,071 - INFO -   score=0.0000
2025-12-19 10:20:34,071 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,072 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,072 - INFO -   score=0.0000
2025-12-19 10:20:34,072 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,072 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,072 - INFO -   score=0.0000
2025-12-19 10:20:34,072 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,072 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,072 - INFO -   score=0.0000
2025-12-19 10:20:34,072 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,073 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,073 - INFO -   score=0.0000
2025-12-19 10:20:34,073 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,073 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,073 - INFO -   score=0.0000
2025-12-19 10:20:34,073 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,074 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,074 - INFO -   score=0.0000
2025-12-19 10:20:34,074 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,074 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,074 - INFO -   score=0.0000
2025-12-19 10:20:34,074 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,074 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,075 - INFO -   score=0.0000
2025-12-19 10:20:34,075 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,075 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,075 - INFO -   score=0.0000
2025-12-19 10:20:34,075 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,075 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,075 - INFO -   score=0.0000
2025-12-19 10:20:34,075 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,076 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,076 - INFO -   score=0.0000
2025-12-19 10:20:34,076 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,076 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,076 - INFO -   score=0.0000
2025-12-19 10:20:34,076 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,077 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,077 - INFO -   score=0.0000
2025-12-19 10:20:34,077 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,077 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,077 - INFO -   score=0.0000
2025-12-19 10:20:34,077 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,077 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,077 - INFO -   score=0.0000
2025-12-19 10:20:34,077 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,078 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,078 - INFO -   score=0.0000
2025-12-19 10:20:34,078 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,078 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,078 - INFO -   score=0.0000
2025-12-19 10:20:34,078 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,078 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,078 - INFO -   score=0.0000
2025-12-19 10:20:34,078 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,079 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,079 - INFO -   score=0.0000
2025-12-19 10:20:34,079 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,079 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,079 - INFO -   score=0.0000
2025-12-19 10:20:34,079 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,079 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,079 - INFO -   score=0.0000
2025-12-19 10:20:34,079 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,080 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,080 - INFO -   score=0.0000
2025-12-19 10:20:34,080 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,080 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,080 - INFO -   score=0.0000
2025-12-19 10:20:34,080 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,080 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,080 - INFO -   score=0.0000
2025-12-19 10:20:34,080 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,081 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,081 - INFO -   score=0.0000
2025-12-19 10:20:34,081 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,081 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,081 - INFO -   score=0.0000
2025-12-19 10:20:34,081 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,081 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,081 - INFO -   score=0.0000
2025-12-19 10:20:34,081 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,082 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,082 - INFO -   score=0.0000
2025-12-19 10:20:34,082 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,082 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,082 - INFO -   score=0.0000
2025-12-19 10:20:34,082 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,082 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,082 - INFO -   score=0.0000
2025-12-19 10:20:34,082 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,082 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,083 - INFO -   score=0.0000
2025-12-19 10:20:34,083 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,083 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,083 - INFO -   score=0.0000
2025-12-19 10:20:34,083 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,083 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,083 - INFO -   score=0.0000
2025-12-19 10:20:34,083 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,083 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,083 - INFO -   score=0.0000
2025-12-19 10:20:34,083 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,084 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,084 - INFO -   score=0.0000
2025-12-19 10:20:34,084 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,084 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,084 - INFO -   score=0.0000
2025-12-19 10:20:34,084 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,085 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,085 - INFO -   score=0.0000
2025-12-19 10:20:34,085 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,085 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,085 - INFO -   score=0.0000
2025-12-19 10:20:34,085 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,085 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,085 - INFO -   score=0.0000
2025-12-19 10:20:34,085 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,086 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,086 - INFO -   score=0.0000
2025-12-19 10:20:34,086 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,086 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,086 - INFO -   score=0.0000
2025-12-19 10:20:34,086 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,086 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,086 - INFO -   score=0.0000
2025-12-19 10:20:34,086 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,087 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,087 - INFO -   score=0.0000
2025-12-19 10:20:34,087 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,087 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,087 - INFO -   score=0.0000
2025-12-19 10:20:34,087 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,087 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,087 - INFO -   score=0.0000
2025-12-19 10:20:34,087 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,088 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,088 - INFO -   score=0.0000
2025-12-19 10:20:34,088 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,088 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,088 - INFO -   score=0.0000
2025-12-19 10:20:34,088 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,088 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,088 - INFO -   score=0.0000
2025-12-19 10:20:34,088 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,089 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,089 - INFO -   score=0.0000
2025-12-19 10:20:34,089 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,089 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,089 - INFO -   score=0.0000
2025-12-19 10:20:34,089 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,089 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,089 - INFO -   score=0.0000
2025-12-19 10:20:34,089 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,090 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,090 - INFO -   score=0.0000
2025-12-19 10:20:34,090 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,090 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,090 - INFO -   score=0.0000
2025-12-19 10:20:34,090 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,091 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,091 - INFO -   score=0.0000
2025-12-19 10:20:34,091 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,091 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,091 - INFO -   score=0.0000
2025-12-19 10:20:34,091 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,091 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,091 - INFO -   score=0.0000
2025-12-19 10:20:34,091 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,092 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,092 - INFO -   score=0.0000
2025-12-19 10:20:34,092 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,092 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,092 - INFO -   score=0.0000
2025-12-19 10:20:34,092 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,092 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,092 - INFO -   score=0.0000
2025-12-19 10:20:34,092 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,093 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,093 - INFO -   score=0.0000
2025-12-19 10:20:34,093 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,093 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,093 - INFO -   score=0.0000
2025-12-19 10:20:34,093 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,093 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,093 - INFO -   score=0.0000
2025-12-19 10:20:34,093 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,094 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,094 - INFO -   score=0.0000
2025-12-19 10:20:34,094 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,094 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,094 - INFO -   score=0.0000
2025-12-19 10:20:34,094 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,094 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,094 - INFO -   score=0.0000
2025-12-19 10:20:34,094 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,095 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,095 - INFO -   score=0.0000
2025-12-19 10:20:34,095 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,095 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,095 - INFO -   score=0.0000
2025-12-19 10:20:34,095 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,095 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,095 - INFO -   score=0.0000
2025-12-19 10:20:34,095 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,096 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,096 - INFO -   score=0.0000
2025-12-19 10:20:34,096 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,096 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,096 - INFO -   score=0.0000
2025-12-19 10:20:34,096 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,097 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,097 - INFO -   score=0.0000
2025-12-19 10:20:34,097 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,097 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,097 - INFO -   score=0.0000
2025-12-19 10:20:34,097 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,098 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,098 - INFO -   score=0.0000
2025-12-19 10:20:34,098 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,098 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,098 - INFO -   score=0.0000
2025-12-19 10:20:34,098 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,098 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,098 - INFO -   score=0.0000
2025-12-19 10:20:34,098 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,099 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,099 - INFO -   score=0.0000
2025-12-19 10:20:34,099 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,099 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,099 - INFO -   score=0.0000
2025-12-19 10:20:34,099 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,099 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,099 - INFO -   score=0.0000
2025-12-19 10:20:34,100 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,100 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,100 - INFO -   score=0.0000
2025-12-19 10:20:34,100 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,100 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,100 - INFO -   score=0.0000
2025-12-19 10:20:34,100 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,101 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,101 - INFO -   score=0.0000
2025-12-19 10:20:34,101 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,101 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,101 - INFO -   score=0.0000
2025-12-19 10:20:34,101 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,102 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,102 - INFO -   score=0.0000
2025-12-19 10:20:34,102 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,102 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,102 - INFO -   score=0.0000
2025-12-19 10:20:34,102 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,102 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,102 - INFO -   score=0.0000
2025-12-19 10:20:34,102 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,103 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,103 - INFO -   score=0.0000
2025-12-19 10:20:34,103 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,103 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,103 - INFO -   score=0.0000
2025-12-19 10:20:34,103 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,103 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,103 - INFO -   score=0.0000
2025-12-19 10:20:34,103 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,103 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,104 - INFO -   score=0.0000
2025-12-19 10:20:34,104 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,104 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,104 - INFO -   score=0.0000
2025-12-19 10:20:34,104 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,104 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,104 - INFO -   score=0.0000
2025-12-19 10:20:34,104 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,104 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,104 - INFO -   score=0.0000
2025-12-19 10:20:34,104 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,105 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,105 - INFO -   score=0.0000
2025-12-19 10:20:34,105 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,105 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,105 - INFO -   score=0.0000
2025-12-19 10:20:34,105 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,105 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,105 - INFO -   score=0.0000
2025-12-19 10:20:34,105 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,106 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,106 - INFO -   score=0.0000
2025-12-19 10:20:34,106 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,106 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,106 - INFO -   score=0.0000
2025-12-19 10:20:34,106 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,106 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,106 - INFO -   score=0.0000
2025-12-19 10:20:34,106 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,107 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,107 - INFO -   score=0.0000
2025-12-19 10:20:34,107 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,107 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,107 - INFO -   score=0.0000
2025-12-19 10:20:34,107 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,107 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,107 - INFO -   score=0.0000
2025-12-19 10:20:34,107 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,108 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,108 - INFO -   score=0.0000
2025-12-19 10:20:34,108 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,108 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,108 - INFO -   score=0.0000
2025-12-19 10:20:34,108 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,108 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,108 - INFO -   score=0.0000
2025-12-19 10:20:34,108 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,108 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,108 - INFO -   score=0.0000
2025-12-19 10:20:34,109 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,109 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,109 - INFO -   score=0.0000
2025-12-19 10:20:34,109 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,109 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,109 - INFO -   score=0.0000
2025-12-19 10:20:34,109 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,109 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,109 - INFO -   score=0.0000
2025-12-19 10:20:34,109 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,110 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,110 - INFO -   score=0.0000
2025-12-19 10:20:34,110 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,110 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,110 - INFO -   score=0.0000
2025-12-19 10:20:34,110 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,110 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,110 - INFO -   score=0.0000
2025-12-19 10:20:34,110 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,111 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,111 - INFO -   score=0.0000
2025-12-19 10:20:34,111 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,111 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,111 - INFO -   score=0.0000
2025-12-19 10:20:34,111 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,111 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,111 - INFO -   score=0.0000
2025-12-19 10:20:34,111 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,112 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,112 - INFO -   score=0.0000
2025-12-19 10:20:34,112 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,112 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,112 - INFO -   score=0.0000
2025-12-19 10:20:34,112 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,112 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,112 - INFO -   score=0.0000
2025-12-19 10:20:34,112 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,113 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,113 - INFO -   score=0.0000
2025-12-19 10:20:34,113 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,113 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,113 - INFO -   score=0.0000
2025-12-19 10:20:34,113 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,113 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,113 - INFO -   score=0.0000
2025-12-19 10:20:34,113 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 10:20:34,114 - INFO -   fit failed: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-12-19 10:20:34,114 - INFO -   score=0.0000
2025-12-19 10:20:34,115 - INFO - 
✓ Stage-2 best config: {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 10:20:34,115 - INFO - 
=== FINAL EXPERIMENTS ===

2025-12-19 10:20:34,115 - INFO - Training RNN for 10 epochs...
2025-12-19 10:23:04,582 - INFO - Using device: cuda
2025-12-19 10:23:05,103 - INFO - Dataset downloaded to: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2
2025-12-19 10:23:05,103 - INFO - ✓ Found dataset at: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2/Dataset.csv
2025-12-19 10:23:06,383 - INFO - ✓ Loaded Dataset: 1552210 rows, 44 columns
2025-12-19 10:23:06,432 - INFO - Shape: (1552210, 43)
2025-12-19 10:23:06,525 - INFO - ✓ Features: 41, Label: SepsisLabel
2025-12-19 10:23:06,526 - INFO - ⏳ Imputing missing values per-patient...
2025-12-19 10:28:00,272 - INFO - Using device: cuda
2025-12-19 10:28:00,648 - INFO - Dataset downloaded to: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2
2025-12-19 10:28:00,648 - INFO - ✓ Found dataset at: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2/Dataset.csv
2025-12-19 10:28:01,899 - INFO - ✓ Loaded Dataset: 1552210 rows, 44 columns
2025-12-19 10:28:01,947 - INFO - Shape: (1552210, 43)
2025-12-19 10:28:02,040 - INFO - ✓ Features: 41, Label: SepsisLabel
2025-12-19 10:28:02,041 - INFO - ⏳ Imputing missing values per-patient...
2025-12-19 10:31:01,292 - INFO - ✓ Imputation complete. NaNs remaining: 0
2025-12-19 10:31:01,292 - INFO - ⏳ Scaling features per-patient...
2025-12-19 11:36:08,654 - INFO - ✓ Scaling complete.
2025-12-19 11:36:08,670 - INFO - ⚠️ Performance Optimization: Reducing dataset from 40336 to 40336 patients (50%)
2025-12-19 12:06:03,513 - INFO - Sequence data created: X_seq (40336, 256, 41), y_seq (40336, 256)
2025-12-19 12:06:05,830 - INFO - Saving preprocessed data to preprocessed_data.pkl...
2025-12-19 12:06:07,916 - INFO - ✓ Data saved to cache.
2025-12-19 12:06:07,987 - INFO - Train: torch.Size([32268, 256, 41]), Val: torch.Size([4033, 256, 41]), Test: torch.Size([4035, 256, 41])
2025-12-19 12:06:07,987 - INFO - === TWO-STAGE HYPERPARAMETER TUNING (PYTORCH) ===

2025-12-19 12:06:07,987 - INFO - STAGE 1: Fast model-family selection

2025-12-19 12:06:07,987 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:06:10,023 - INFO -   score=0.9333
2025-12-19 12:06:10,025 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:06:11,203 - INFO -   score=0.8934
2025-12-19 12:06:11,205 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:06:12,351 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.71 GiB is free. Process 1687 has 70.34 MiB memory in use. Including non-PyTorch memory, this process has 834.00 MiB memory in use. Of the allocated memory 597.38 MiB is allocated by PyTorch, and 54.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:06:12,450 - INFO -   score=0.0000
2025-12-19 12:06:12,451 - INFO - 
✓ Stage-1 winner: RNN (score=0.9333)

2025-12-19 12:06:12,451 - INFO - STAGE 2: Exhaustive search for winner

2025-12-19 12:06:12,451 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:06:16,175 - INFO -   score=0.9875
2025-12-19 12:06:16,176 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:06:19,963 - INFO -   score=0.9862
2025-12-19 12:06:19,963 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:06:23,710 - INFO -   score=0.9472
2025-12-19 12:06:23,710 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:06:27,432 - INFO -   score=0.9652
2025-12-19 12:06:27,432 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:06:31,101 - INFO -   score=0.9240
2025-12-19 12:06:31,101 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:06:34,778 - INFO -   score=0.9099
2025-12-19 12:06:34,779 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:06:38,459 - INFO -   score=0.9581
2025-12-19 12:06:38,459 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:06:42,173 - INFO -   score=0.9568
2025-12-19 12:06:42,173 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:06:45,963 - INFO -   score=0.9795
2025-12-19 12:06:45,963 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:06:49,682 - INFO -   score=0.9833
2025-12-19 12:06:49,682 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:06:53,366 - INFO -   score=0.9585
2025-12-19 12:06:53,366 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:06:57,102 - INFO -   score=0.9787
2025-12-19 12:06:57,102 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:07:00,961 - INFO -   score=0.9357
2025-12-19 12:07:00,961 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:07:04,839 - INFO -   score=0.9297
2025-12-19 12:07:04,839 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:07:08,718 - INFO -   score=0.9591
2025-12-19 12:07:08,718 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:07:12,627 - INFO -   score=0.9587
2025-12-19 12:07:12,627 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:07:16,265 - INFO -   score=0.6634
2025-12-19 12:07:16,266 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:07:19,867 - INFO -   score=0.6521
2025-12-19 12:07:19,867 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:07:23,484 - INFO -   score=0.6323
2025-12-19 12:07:23,484 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:07:27,168 - INFO -   score=0.6375
2025-12-19 12:07:27,168 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:07:30,975 - INFO -   score=0.5000
2025-12-19 12:07:30,975 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:07:34,803 - INFO -   score=0.5002
2025-12-19 12:07:34,803 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:07:38,667 - INFO -   score=0.5016
2025-12-19 12:07:38,667 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:07:42,540 - INFO -   score=0.5000
2025-12-19 12:07:42,541 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:07:46,252 - INFO -   score=0.9880
2025-12-19 12:07:46,253 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:07:50,034 - INFO -   score=0.9880
2025-12-19 12:07:50,034 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:07:53,727 - INFO -   score=0.9574
2025-12-19 12:07:53,727 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:07:57,501 - INFO -   score=0.9628
2025-12-19 12:07:57,501 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:08:01,251 - INFO -   score=0.9436
2025-12-19 12:08:01,251 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:08:04,955 - INFO -   score=0.9135
2025-12-19 12:08:04,955 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:08:08,623 - INFO -   score=0.9542
2025-12-19 12:08:08,623 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:08:12,350 - INFO -   score=0.9630
2025-12-19 12:08:12,350 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:08:16,088 - INFO -   score=0.9733
2025-12-19 12:08:16,088 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:08:19,822 - INFO -   score=0.9617
2025-12-19 12:08:19,822 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:08:23,570 - INFO -   score=0.9535
2025-12-19 12:08:23,570 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:08:27,299 - INFO -   score=0.9612
2025-12-19 12:08:27,300 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:08:31,102 - INFO -   score=0.9287
2025-12-19 12:08:31,102 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:08:34,987 - INFO -   score=0.9395
2025-12-19 12:08:34,987 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:08:38,894 - INFO -   score=0.9554
2025-12-19 12:08:38,894 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:08:42,776 - INFO -   score=0.9603
2025-12-19 12:08:42,776 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:08:46,393 - INFO -   score=0.6496
2025-12-19 12:08:46,393 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:08:50,065 - INFO -   score=0.6629
2025-12-19 12:08:50,065 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:08:53,677 - INFO -   score=0.6178
2025-12-19 12:08:53,677 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:08:57,346 - INFO -   score=0.6422
2025-12-19 12:08:57,346 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:09:01,157 - INFO -   score=0.5041
2025-12-19 12:09:01,157 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:09:05,025 - INFO -   score=0.5000
2025-12-19 12:09:05,025 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:09:08,908 - INFO -   score=0.5034
2025-12-19 12:09:08,908 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:09:12,711 - INFO -   score=0.5070
2025-12-19 12:09:12,711 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:09:15,137 - INFO -   score=0.9852
2025-12-19 12:09:15,137 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:09:17,600 - INFO -   score=0.9632
2025-12-19 12:09:17,600 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:09:20,034 - INFO -   score=0.9535
2025-12-19 12:09:20,034 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:09:22,489 - INFO -   score=0.9502
2025-12-19 12:09:22,489 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:09:24,901 - INFO -   score=0.9348
2025-12-19 12:09:24,901 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:09:27,379 - INFO -   score=0.9232
2025-12-19 12:09:27,379 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:09:29,833 - INFO -   score=0.9563
2025-12-19 12:09:29,833 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:09:32,334 - INFO -   score=0.9565
2025-12-19 12:09:32,335 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:09:34,752 - INFO -   score=0.9750
2025-12-19 12:09:34,752 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:09:37,204 - INFO -   score=0.9731
2025-12-19 12:09:37,204 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:09:39,655 - INFO -   score=0.9628
2025-12-19 12:09:39,655 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:09:42,104 - INFO -   score=0.9600
2025-12-19 12:09:42,104 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:09:44,647 - INFO -   score=0.9406
2025-12-19 12:09:44,647 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:09:47,203 - INFO -   score=0.9388
2025-12-19 12:09:47,203 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:09:49,788 - INFO -   score=0.9584
2025-12-19 12:09:49,788 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:09:52,388 - INFO -   score=0.9601
2025-12-19 12:09:52,389 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:09:54,779 - INFO -   score=0.6476
2025-12-19 12:09:54,779 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:09:57,221 - INFO -   score=0.6791
2025-12-19 12:09:57,221 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:09:59,580 - INFO -   score=0.6682
2025-12-19 12:09:59,580 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:10:01,993 - INFO -   score=0.6343
2025-12-19 12:10:01,993 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:10:04,445 - INFO -   score=0.5002
2025-12-19 12:10:04,445 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:10:06,932 - INFO -   score=0.5020
2025-12-19 12:10:06,932 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:10:09,468 - INFO -   score=0.5071
2025-12-19 12:10:09,468 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:10:12,001 - INFO -   score=0.5000
2025-12-19 12:10:12,001 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:10:14,495 - INFO -   score=0.9480
2025-12-19 12:10:14,495 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:10:16,957 - INFO -   score=0.9845
2025-12-19 12:10:16,957 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:10:19,409 - INFO -   score=0.9518
2025-12-19 12:10:19,410 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:10:21,885 - INFO -   score=0.9512
2025-12-19 12:10:21,885 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:10:24,309 - INFO -   score=0.9266
2025-12-19 12:10:24,309 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:10:26,838 - INFO -   score=0.9275
2025-12-19 12:10:26,839 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:10:29,310 - INFO -   score=0.9582
2025-12-19 12:10:29,310 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:10:31,822 - INFO -   score=0.9568
2025-12-19 12:10:31,822 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:10:34,301 - INFO -   score=0.9686
2025-12-19 12:10:34,301 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:10:36,776 - INFO -   score=0.9703
2025-12-19 12:10:36,776 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:10:39,243 - INFO -   score=0.9009
2025-12-19 12:10:39,243 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:10:41,771 - INFO -   score=0.9607
2025-12-19 12:10:41,771 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:10:44,308 - INFO -   score=0.9459
2025-12-19 12:10:44,308 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:10:46,843 - INFO -   score=0.9406
2025-12-19 12:10:46,843 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:10:49,377 - INFO -   score=0.9593
2025-12-19 12:10:49,377 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:10:51,969 - INFO -   score=0.9598
2025-12-19 12:10:51,969 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:10:54,351 - INFO -   score=0.7002
2025-12-19 12:10:54,351 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:10:56,748 - INFO -   score=0.6582
2025-12-19 12:10:56,748 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:10:59,122 - INFO -   score=0.6077
2025-12-19 12:10:59,122 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:11:01,492 - INFO -   score=0.6370
2025-12-19 12:11:01,492 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:11:03,974 - INFO -   score=0.5192
2025-12-19 12:11:03,974 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:11:06,456 - INFO -   score=0.5000
2025-12-19 12:11:06,456 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:11:08,898 - INFO -   score=0.5014
2025-12-19 12:11:08,898 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:11:11,390 - INFO -   score=0.5002
2025-12-19 12:11:11,391 - INFO - 
✓ Stage-2 best config: {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:11:11,391 - INFO - 
=== FINAL EXPERIMENTS ===

2025-12-19 12:11:11,391 - INFO - Training RNN for 10 epochs...
2025-12-19 12:11:24,229 - INFO -   Test AUC: 0.9885, F1: 0.2465
2025-12-19 12:11:24,229 - INFO - Training RNN for 20 epochs...
2025-12-19 12:11:47,973 - INFO -   Test AUC: 0.9888, F1: 0.1846
2025-12-19 12:11:47,973 - INFO - Preparing data for PhysioNet Official Scoring...
2025-12-19 12:11:47,994 - INFO - Scoring on 4035 test patients...
2025-12-19 12:13:52,955 - INFO - Using device: cuda
2025-12-19 12:13:52,956 - INFO - Loading preprocessed data from preprocessed_data.pkl...
2025-12-19 12:13:53,479 - INFO - ✓ Data loaded from cache.
2025-12-19 12:13:53,479 - INFO - Train: torch.Size([32268, 256, 41]), Val: torch.Size([4033, 256, 41]), Test: torch.Size([4035, 256, 41])
2025-12-19 12:13:53,479 - INFO - === TWO-STAGE HYPERPARAMETER TUNING (PYTORCH) ===

2025-12-19 12:13:53,479 - INFO - STAGE 1: Fast model-family selection

2025-12-19 12:13:53,479 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:13:54,851 - INFO -   score=0.9333
2025-12-19 12:13:54,853 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:13:55,666 - INFO -   score=0.8941
2025-12-19 12:13:55,668 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:13:56,557 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 5.02 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 834.00 MiB memory in use. Of the allocated memory 597.38 MiB is allocated by PyTorch, and 54.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:13:56,578 - INFO -   score=0.0000
2025-12-19 12:13:56,579 - INFO - 
✓ Stage-1 winner: RNN (score=0.9333)

2025-12-19 12:13:56,579 - INFO - STAGE 2: Exhaustive search for winner

2025-12-19 12:13:56,579 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:13:59,947 - INFO -   score=0.9875
2025-12-19 12:13:59,948 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:14:03,350 - INFO -   score=0.9862
2025-12-19 12:14:03,351 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:14:06,757 - INFO -   score=0.9472
2025-12-19 12:14:06,757 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:14:10,146 - INFO -   score=0.9652
2025-12-19 12:14:10,146 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:14:13,477 - INFO -   score=0.9240
2025-12-19 12:14:13,477 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:14:16,924 - INFO -   score=0.9099
2025-12-19 12:14:16,925 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:14:20,317 - INFO -   score=0.9581
2025-12-19 12:14:20,317 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:14:23,694 - INFO -   score=0.9568
2025-12-19 12:14:23,694 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:14:27,144 - INFO -   score=0.9795
2025-12-19 12:14:27,144 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:14:30,566 - INFO -   score=0.9833
2025-12-19 12:14:30,566 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:14:33,929 - INFO -   score=0.9585
2025-12-19 12:14:33,930 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:14:37,330 - INFO -   score=0.9787
2025-12-19 12:14:37,330 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:14:40,864 - INFO -   score=0.9357
2025-12-19 12:14:40,864 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:14:44,395 - INFO -   score=0.9297
2025-12-19 12:14:44,395 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:14:47,965 - INFO -   score=0.9591
2025-12-19 12:14:47,965 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:14:51,676 - INFO -   score=0.9587
2025-12-19 12:14:51,676 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:14:54,996 - INFO -   score=0.6634
2025-12-19 12:14:54,996 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:14:58,415 - INFO -   score=0.6521
2025-12-19 12:14:58,415 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:15:01,739 - INFO -   score=0.6323
2025-12-19 12:15:01,739 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:15:05,082 - INFO -   score=0.6375
2025-12-19 12:15:05,082 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:15:08,533 - INFO -   score=0.5000
2025-12-19 12:15:08,533 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:15:12,074 - INFO -   score=0.5002
2025-12-19 12:15:12,075 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:15:15,599 - INFO -   score=0.5016
2025-12-19 12:15:15,600 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:15:19,125 - INFO -   score=0.5000
2025-12-19 12:15:19,125 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:15:22,524 - INFO -   score=0.9880
2025-12-19 12:15:22,525 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:15:26,016 - INFO -   score=0.9880
2025-12-19 12:15:26,016 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:15:29,467 - INFO -   score=0.9574
2025-12-19 12:15:29,467 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:15:32,992 - INFO -   score=0.9628
2025-12-19 12:15:32,992 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:15:36,464 - INFO -   score=0.9436
2025-12-19 12:15:36,464 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:15:39,939 - INFO -   score=0.9135
2025-12-19 12:15:39,939 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:15:43,377 - INFO -   score=0.9542
2025-12-19 12:15:43,377 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:15:46,820 - INFO -   score=0.9630
2025-12-19 12:15:46,820 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:15:50,246 - INFO -   score=0.9733
2025-12-19 12:15:50,246 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:15:53,703 - INFO -   score=0.9617
2025-12-19 12:15:53,703 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:15:57,096 - INFO -   score=0.9535
2025-12-19 12:15:57,096 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:16:00,569 - INFO -   score=0.9612
2025-12-19 12:16:00,569 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:16:04,144 - INFO -   score=0.9287
2025-12-19 12:16:04,144 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:16:07,787 - INFO -   score=0.9395
2025-12-19 12:16:07,787 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:16:11,413 - INFO -   score=0.9554
2025-12-19 12:16:11,413 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:16:15,022 - INFO -   score=0.9603
2025-12-19 12:16:15,022 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:16:18,337 - INFO -   score=0.6496
2025-12-19 12:16:18,337 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:16:21,818 - INFO -   score=0.6629
2025-12-19 12:16:21,818 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:16:25,169 - INFO -   score=0.6178
2025-12-19 12:16:25,169 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:16:28,572 - INFO -   score=0.6422
2025-12-19 12:16:28,572 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:16:32,137 - INFO -   score=0.5041
2025-12-19 12:16:32,138 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:16:35,703 - INFO -   score=0.5000
2025-12-19 12:16:35,704 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:16:39,264 - INFO -   score=0.5034
2025-12-19 12:16:39,264 - INFO - [RNN_big] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:16:42,816 - INFO -   score=0.5070
2025-12-19 12:16:42,816 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:16:44,977 - INFO -   score=0.9852
2025-12-19 12:16:44,977 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:16:47,142 - INFO -   score=0.9632
2025-12-19 12:16:47,142 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:16:49,292 - INFO -   score=0.9535
2025-12-19 12:16:49,292 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:16:51,431 - INFO -   score=0.9502
2025-12-19 12:16:51,431 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:16:53,546 - INFO -   score=0.9348
2025-12-19 12:16:53,547 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:16:55,685 - INFO -   score=0.9232
2025-12-19 12:16:55,685 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:16:57,802 - INFO -   score=0.9563
2025-12-19 12:16:57,802 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:16:59,963 - INFO -   score=0.9565
2025-12-19 12:16:59,963 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:17:02,116 - INFO -   score=0.9750
2025-12-19 12:17:02,116 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:17:04,307 - INFO -   score=0.9731
2025-12-19 12:17:04,307 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:17:06,443 - INFO -   score=0.9628
2025-12-19 12:17:06,443 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:17:08,598 - INFO -   score=0.9600
2025-12-19 12:17:08,598 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:17:10,782 - INFO -   score=0.9406
2025-12-19 12:17:10,782 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:17:12,983 - INFO -   score=0.9388
2025-12-19 12:17:12,983 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:17:15,164 - INFO -   score=0.9584
2025-12-19 12:17:15,164 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:17:17,390 - INFO -   score=0.9601
2025-12-19 12:17:17,390 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:17:19,457 - INFO -   score=0.6476
2025-12-19 12:17:19,457 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:17:21,542 - INFO -   score=0.6791
2025-12-19 12:17:21,542 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:17:23,605 - INFO -   score=0.6682
2025-12-19 12:17:23,605 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:17:25,667 - INFO -   score=0.6343
2025-12-19 12:17:25,667 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:17:27,809 - INFO -   score=0.5002
2025-12-19 12:17:27,809 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:17:29,983 - INFO -   score=0.5020
2025-12-19 12:17:29,983 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:17:32,153 - INFO -   score=0.5071
2025-12-19 12:17:32,153 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:17:34,344 - INFO -   score=0.5000
2025-12-19 12:17:34,344 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:17:36,459 - INFO -   score=0.9480
2025-12-19 12:17:36,460 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:17:38,636 - INFO -   score=0.9845
2025-12-19 12:17:38,636 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:17:40,784 - INFO -   score=0.9518
2025-12-19 12:17:40,784 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:17:42,981 - INFO -   score=0.9512
2025-12-19 12:17:42,981 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:17:45,092 - INFO -   score=0.9266
2025-12-19 12:17:45,092 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:17:47,190 - INFO -   score=0.9275
2025-12-19 12:17:47,190 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:17:49,291 - INFO -   score=0.9582
2025-12-19 12:17:49,291 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:17:51,443 - INFO -   score=0.9568
2025-12-19 12:17:51,443 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:17:53,553 - INFO -   score=0.9686
2025-12-19 12:17:53,553 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:17:55,689 - INFO -   score=0.9703
2025-12-19 12:17:55,689 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:17:57,809 - INFO -   score=0.9009
2025-12-19 12:17:57,809 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:17:59,955 - INFO -   score=0.9607
2025-12-19 12:17:59,955 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:18:02,094 - INFO -   score=0.9459
2025-12-19 12:18:02,094 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:18:04,288 - INFO -   score=0.9406
2025-12-19 12:18:04,288 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:18:06,507 - INFO -   score=0.9593
2025-12-19 12:18:06,507 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:18:08,693 - INFO -   score=0.9598
2025-12-19 12:18:08,693 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:18:10,743 - INFO -   score=0.7002
2025-12-19 12:18:10,743 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:18:12,808 - INFO -   score=0.6582
2025-12-19 12:18:12,808 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:18:14,837 - INFO -   score=0.6077
2025-12-19 12:18:14,837 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:18:16,914 - INFO -   score=0.6370
2025-12-19 12:18:16,914 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:18:19,039 - INFO -   score=0.5192
2025-12-19 12:18:19,039 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:18:21,189 - INFO -   score=0.5000
2025-12-19 12:18:21,189 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:18:23,326 - INFO -   score=0.5014
2025-12-19 12:18:23,326 - INFO - [RNN_big] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:18:25,452 - INFO -   score=0.5002
2025-12-19 12:18:25,453 - INFO - 
✓ Stage-2 best config: {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:18:25,453 - INFO - 
=== FINAL EXPERIMENTS ===

2025-12-19 12:18:25,453 - INFO - Training RNN for 10 epochs...
2025-12-19 12:18:37,961 - INFO -   Test AUC: 0.9885, F1: 0.2465
2025-12-19 12:18:37,961 - INFO - Training RNN for 20 epochs...
2025-12-19 12:19:01,447 - INFO -   Test AUC: 0.9888, F1: 0.1846
2025-12-19 12:19:01,447 - INFO - Preparing data for PhysioNet Official Scoring...
2025-12-19 12:19:01,467 - INFO - Scoring on 4035 test patients...
2025-12-19 12:19:01,531 - INFO - 
========================================
2025-12-19 12:19:01,531 - INFO - OFFICIAL PHYSIONET UTILITY SCORE
2025-12-19 12:19:01,531 - INFO - ========================================
2025-12-19 12:19:01,531 - INFO - Model: RNN
2025-12-19 12:19:01,531 - INFO - Normalized Utility Score: 0.0100
2025-12-19 12:19:01,531 - INFO - Raw Utility Score:        32.18
2025-12-19 12:19:01,531 - INFO - ----------------------------------------
2025-12-19 12:19:01,531 - INFO - Note: A score > 0.0 means better than doing nothing.
2025-12-19 12:19:01,531 - INFO -       A score of 1.0 is perfect prediction.
2025-12-19 12:19:01,531 - INFO - ========================================
2025-12-19 12:19:01,531 - INFO - 
Generating Plots...
2025-12-19 12:19:01,614 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-12-19 12:19:01,617 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-12-19 12:24:47,525 - INFO - Using device: cuda
2025-12-19 12:24:47,526 - INFO - Loading preprocessed data from preprocessed_data.pkl...
2025-12-19 12:24:47,949 - INFO - ✓ Data loaded from cache.
2025-12-19 12:24:47,949 - INFO - Train: torch.Size([32268, 256, 41]), Val: torch.Size([4033, 256, 41]), Test: torch.Size([4035, 256, 41])
2025-12-19 12:24:47,949 - INFO - === FULL GRID SEARCH ON ALL MODELS (PYTORCH) ===

2025-12-19 12:24:47,949 - INFO - --- Tuning RNN ---
2025-12-19 12:24:47,949 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:24:51,952 - INFO -   score=0.9853
2025-12-19 12:24:51,953 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:24:55,378 - INFO -   score=0.9871
2025-12-19 12:24:55,379 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:24:58,725 - INFO -   score=0.9484
2025-12-19 12:24:58,726 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:25:02,181 - INFO -   score=0.9649
2025-12-19 12:25:02,181 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:25:05,516 - INFO -   score=0.9201
2025-12-19 12:25:05,516 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:25:08,874 - INFO -   score=0.9075
2025-12-19 12:25:08,874 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:25:12,217 - INFO -   score=0.9598
2025-12-19 12:25:12,217 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:25:15,585 - INFO -   score=0.9588
2025-12-19 12:25:15,586 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:25:18,931 - INFO -   score=0.9791
2025-12-19 12:25:18,931 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:25:22,271 - INFO -   score=0.9742
2025-12-19 12:25:22,272 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:25:25,590 - INFO -   score=0.9645
2025-12-19 12:25:25,591 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:25:28,930 - INFO -   score=0.9779
2025-12-19 12:25:28,930 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:25:32,447 - INFO -   score=0.9324
2025-12-19 12:25:32,448 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:25:35,972 - INFO -   score=0.9337
2025-12-19 12:25:35,972 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:25:39,519 - INFO -   score=0.9577
2025-12-19 12:25:39,519 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:25:43,073 - INFO -   score=0.9573
2025-12-19 12:25:43,073 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:25:46,336 - INFO -   score=0.6686
2025-12-19 12:25:46,336 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:25:49,646 - INFO -   score=0.7143
2025-12-19 12:25:49,646 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:25:52,907 - INFO -   score=0.6540
2025-12-19 12:25:52,907 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:25:56,246 - INFO -   score=0.6394
2025-12-19 12:25:56,246 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:25:59,666 - INFO -   score=0.5011
2025-12-19 12:25:59,666 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:26:03,138 - INFO -   score=0.5013
2025-12-19 12:26:03,139 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:26:06,593 - INFO -   score=0.5043
2025-12-19 12:26:06,593 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:26:10,081 - INFO -   score=0.5057
2025-12-19 12:26:10,081 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:26:13,441 - INFO -   score=0.9888
2025-12-19 12:26:13,442 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:26:16,887 - INFO -   score=0.9871
2025-12-19 12:26:16,887 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:26:20,327 - INFO -   score=0.9512
2025-12-19 12:26:20,328 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:26:23,736 - INFO -   score=0.9637
2025-12-19 12:26:23,737 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:26:27,062 - INFO -   score=0.9269
2025-12-19 12:26:27,062 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:26:30,417 - INFO -   score=0.9114
2025-12-19 12:26:30,418 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:26:33,714 - INFO -   score=0.9521
2025-12-19 12:26:33,714 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:26:37,065 - INFO -   score=0.9559
2025-12-19 12:26:37,065 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:26:40,426 - INFO -   score=0.9855
2025-12-19 12:26:40,427 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:26:43,833 - INFO -   score=0.9774
2025-12-19 12:26:43,834 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:26:47,204 - INFO -   score=0.9694
2025-12-19 12:26:47,204 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:26:50,580 - INFO -   score=0.9754
2025-12-19 12:26:50,580 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:26:54,170 - INFO -   score=0.9399
2025-12-19 12:26:54,170 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:26:57,678 - INFO -   score=0.9390
2025-12-19 12:26:57,679 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:27:01,155 - INFO -   score=0.9581
2025-12-19 12:27:01,155 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:27:04,654 - INFO -   score=0.9577
2025-12-19 12:27:04,654 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:27:07,890 - INFO -   score=0.6970
2025-12-19 12:27:07,890 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:27:11,172 - INFO -   score=0.6693
2025-12-19 12:27:11,172 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:27:14,443 - INFO -   score=0.6184
2025-12-19 12:27:14,444 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:27:18,040 - INFO -   score=0.6360
2025-12-19 12:27:18,041 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:27:21,624 - INFO -   score=0.5018
2025-12-19 12:27:21,624 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:27:25,218 - INFO -   score=0.5000
2025-12-19 12:27:25,218 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:27:29,060 - INFO -   score=0.5004
2025-12-19 12:27:29,060 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:27:33,225 - INFO -   score=0.5007
2025-12-19 12:27:33,225 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:27:35,421 - INFO -   score=0.9861
2025-12-19 12:27:35,422 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:27:37,609 - INFO -   score=0.9779
2025-12-19 12:27:37,610 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:27:40,174 - INFO -   score=0.9549
2025-12-19 12:27:40,174 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:27:42,665 - INFO -   score=0.9603
2025-12-19 12:27:42,665 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:27:44,952 - INFO -   score=0.9429
2025-12-19 12:27:44,953 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:27:47,144 - INFO -   score=0.9328
2025-12-19 12:27:47,145 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:27:49,275 - INFO -   score=0.9573
2025-12-19 12:27:49,275 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:27:51,492 - INFO -   score=0.9597
2025-12-19 12:27:51,492 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:27:53,686 - INFO -   score=0.9791
2025-12-19 12:27:53,686 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:27:56,012 - INFO -   score=0.9765
2025-12-19 12:27:56,012 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:27:58,319 - INFO -   score=0.9553
2025-12-19 12:27:58,319 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:28:00,564 - INFO -   score=0.9550
2025-12-19 12:28:00,564 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:28:02,966 - INFO -   score=0.9428
2025-12-19 12:28:02,966 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:28:05,884 - INFO -   score=0.9349
2025-12-19 12:28:05,884 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:28:08,616 - INFO -   score=0.9551
2025-12-19 12:28:08,616 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:28:10,935 - INFO -   score=0.9578
2025-12-19 12:28:10,935 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:28:13,040 - INFO -   score=0.6519
2025-12-19 12:28:13,040 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:28:15,202 - INFO -   score=0.6306
2025-12-19 12:28:15,202 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:28:17,338 - INFO -   score=0.6115
2025-12-19 12:28:17,338 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:28:19,487 - INFO -   score=0.6606
2025-12-19 12:28:19,487 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:28:21,724 - INFO -   score=0.5014
2025-12-19 12:28:21,724 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:28:23,977 - INFO -   score=0.5057
2025-12-19 12:28:23,977 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:28:26,163 - INFO -   score=0.5009
2025-12-19 12:28:26,163 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:28:28,743 - INFO -   score=0.5009
2025-12-19 12:28:28,743 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:28:31,312 - INFO -   score=0.9841
2025-12-19 12:28:31,313 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:28:33,976 - INFO -   score=0.9861
2025-12-19 12:28:33,976 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:28:36,283 - INFO -   score=0.9534
2025-12-19 12:28:36,283 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:28:39,047 - INFO -   score=0.9584
2025-12-19 12:28:39,048 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:28:41,654 - INFO -   score=0.9319
2025-12-19 12:28:41,654 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:28:44,316 - INFO -   score=0.9285
2025-12-19 12:28:44,316 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:28:46,856 - INFO -   score=0.9539
2025-12-19 12:28:46,856 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:28:49,531 - INFO -   score=0.9591
2025-12-19 12:28:49,531 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:28:52,120 - INFO -   score=0.9797
2025-12-19 12:28:52,120 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:28:54,841 - INFO -   score=0.9796
2025-12-19 12:28:54,841 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:28:57,413 - INFO -   score=0.9344
2025-12-19 12:28:57,413 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:29:00,111 - INFO -   score=0.9623
2025-12-19 12:29:00,112 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:29:02,748 - INFO -   score=0.9439
2025-12-19 12:29:02,748 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:29:05,469 - INFO -   score=0.9403
2025-12-19 12:29:05,469 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:29:08,068 - INFO -   score=0.9614
2025-12-19 12:29:08,068 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:29:10,812 - INFO -   score=0.9591
2025-12-19 12:29:10,812 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:29:13,245 - INFO -   score=0.6373
2025-12-19 12:29:13,245 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:29:15,875 - INFO -   score=0.6755
2025-12-19 12:29:15,875 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:29:18,375 - INFO -   score=0.5926
2025-12-19 12:29:18,375 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:29:20,915 - INFO -   score=0.6472
2025-12-19 12:29:20,915 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:29:23,351 - INFO -   score=0.5018
2025-12-19 12:29:23,351 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:29:25,872 - INFO -   score=0.5000
2025-12-19 12:29:25,872 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:29:28,516 - INFO -   score=0.5005
2025-12-19 12:29:28,516 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:29:31,326 - INFO -   score=0.5002
2025-12-19 12:29:31,328 - INFO - 
--- Tuning CNN ---
2025-12-19 12:29:31,328 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:29:35,739 - INFO -   score=0.9896
2025-12-19 12:29:35,740 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:29:39,851 - INFO -   score=0.8433
2025-12-19 12:29:39,851 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:29:43,952 - INFO -   score=0.0732
2025-12-19 12:29:43,952 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:29:47,909 - INFO -   score=0.0644
2025-12-19 12:29:47,909 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:29:51,931 - INFO -   score=0.9871
2025-12-19 12:29:51,931 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:29:55,922 - INFO -   score=0.9682
2025-12-19 12:29:55,922 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:30:00,096 - INFO -   score=0.0786
2025-12-19 12:30:00,097 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:30:04,259 - INFO -   score=0.0745
2025-12-19 12:30:04,259 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:30:07,736 - INFO -   score=0.5000
2025-12-19 12:30:07,736 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:30:11,334 - INFO -   score=0.8237
2025-12-19 12:30:11,334 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:30:15,764 - INFO -   score=0.5000
2025-12-19 12:30:15,764 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:30:19,542 - INFO -   score=0.5000
2025-12-19 12:30:19,542 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:30:23,668 - INFO -   score=0.9898
2025-12-19 12:30:23,669 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:30:27,852 - INFO -   score=0.8697
2025-12-19 12:30:27,852 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:30:32,010 - INFO -   score=0.0660
2025-12-19 12:30:32,010 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:30:36,118 - INFO -   score=0.0655
2025-12-19 12:30:36,118 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:30:39,454 - INFO -   score=0.9886
2025-12-19 12:30:39,454 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:30:42,799 - INFO -   score=0.9737
2025-12-19 12:30:42,799 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:30:46,332 - INFO -   score=0.0783
2025-12-19 12:30:46,332 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:30:49,839 - INFO -   score=0.0767
2025-12-19 12:30:49,839 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:30:53,015 - INFO -   score=0.5000
2025-12-19 12:30:53,015 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:30:56,265 - INFO -   score=0.8228
2025-12-19 12:30:56,266 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:30:59,678 - INFO -   score=0.5000
2025-12-19 12:30:59,678 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:03,073 - INFO -   score=0.5000
2025-12-19 12:31:03,073 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:08,124 - INFO -   fit failed: Pin memory thread exited unexpectedly
2025-12-19 12:31:08,145 - INFO -   score=0.0000
2025-12-19 12:31:08,145 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:08,170 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,171 - INFO -   score=0.0000
2025-12-19 12:31:08,171 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:08,195 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,196 - INFO -   score=0.0000
2025-12-19 12:31:08,196 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:08,221 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,222 - INFO -   score=0.0000
2025-12-19 12:31:08,222 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:08,246 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,247 - INFO -   score=0.0000
2025-12-19 12:31:08,247 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:08,271 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,272 - INFO -   score=0.0000
2025-12-19 12:31:08,272 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:08,317 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,319 - INFO -   score=0.0000
2025-12-19 12:31:08,319 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:08,357 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,359 - INFO -   score=0.0000
2025-12-19 12:31:08,359 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:08,382 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,384 - INFO -   score=0.0000
2025-12-19 12:31:08,384 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:08,407 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,409 - INFO -   score=0.0000
2025-12-19 12:31:08,409 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:08,447 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,448 - INFO -   score=0.0000
2025-12-19 12:31:08,449 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:08,488 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,489 - INFO -   score=0.0000
2025-12-19 12:31:08,489 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:08,513 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,514 - INFO -   score=0.0000
2025-12-19 12:31:08,514 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:08,538 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,539 - INFO -   score=0.0000
2025-12-19 12:31:08,539 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:08,563 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,564 - INFO -   score=0.0000
2025-12-19 12:31:08,564 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:08,588 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,589 - INFO -   score=0.0000
2025-12-19 12:31:08,589 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:08,612 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,614 - INFO -   score=0.0000
2025-12-19 12:31:08,614 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:08,638 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,639 - INFO -   score=0.0000
2025-12-19 12:31:08,639 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:08,679 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,680 - INFO -   score=0.0000
2025-12-19 12:31:08,680 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:08,719 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,721 - INFO -   score=0.0000
2025-12-19 12:31:08,721 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:08,745 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,746 - INFO -   score=0.0000
2025-12-19 12:31:08,746 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:08,770 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,771 - INFO -   score=0.0000
2025-12-19 12:31:08,771 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:08,811 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,812 - INFO -   score=0.0000
2025-12-19 12:31:08,812 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:08,851 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,853 - INFO -   score=0.0000
2025-12-19 12:31:08,853 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:08,877 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,878 - INFO -   score=0.0000
2025-12-19 12:31:08,878 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:08,901 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,902 - INFO -   score=0.0000
2025-12-19 12:31:08,902 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:08,926 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,927 - INFO -   score=0.0000
2025-12-19 12:31:08,927 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:08,950 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,951 - INFO -   score=0.0000
2025-12-19 12:31:08,951 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:08,975 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:08,976 - INFO -   score=0.0000
2025-12-19 12:31:08,976 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:09,000 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,001 - INFO -   score=0.0000
2025-12-19 12:31:09,001 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:09,042 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,043 - INFO -   score=0.0000
2025-12-19 12:31:09,043 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:09,082 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,083 - INFO -   score=0.0000
2025-12-19 12:31:09,083 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:09,107 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,109 - INFO -   score=0.0000
2025-12-19 12:31:09,109 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:09,132 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,134 - INFO -   score=0.0000
2025-12-19 12:31:09,134 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:09,173 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,174 - INFO -   score=0.0000
2025-12-19 12:31:09,174 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:09,214 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,215 - INFO -   score=0.0000
2025-12-19 12:31:09,215 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:09,239 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,240 - INFO -   score=0.0000
2025-12-19 12:31:09,241 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:09,264 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,266 - INFO -   score=0.0000
2025-12-19 12:31:09,266 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:09,289 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,291 - INFO -   score=0.0000
2025-12-19 12:31:09,291 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:09,315 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,316 - INFO -   score=0.0000
2025-12-19 12:31:09,316 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:09,340 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,341 - INFO -   score=0.0000
2025-12-19 12:31:09,341 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:09,365 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,366 - INFO -   score=0.0000
2025-12-19 12:31:09,366 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:09,406 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,408 - INFO -   score=0.0000
2025-12-19 12:31:09,408 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:09,447 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,449 - INFO -   score=0.0000
2025-12-19 12:31:09,449 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:09,473 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,474 - INFO -   score=0.0000
2025-12-19 12:31:09,474 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:09,498 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,499 - INFO -   score=0.0000
2025-12-19 12:31:09,499 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:09,539 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,540 - INFO -   score=0.0000
2025-12-19 12:31:09,540 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:09,579 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,581 - INFO -   score=0.0000
2025-12-19 12:31:09,581 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:09,604 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,605 - INFO -   score=0.0000
2025-12-19 12:31:09,606 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:09,629 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,630 - INFO -   score=0.0000
2025-12-19 12:31:09,631 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:09,654 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,655 - INFO -   score=0.0000
2025-12-19 12:31:09,655 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:09,679 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,680 - INFO -   score=0.0000
2025-12-19 12:31:09,680 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:09,704 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,705 - INFO -   score=0.0000
2025-12-19 12:31:09,705 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:09,729 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,730 - INFO -   score=0.0000
2025-12-19 12:31:09,730 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:09,771 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,773 - INFO -   score=0.0000
2025-12-19 12:31:09,773 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:09,814 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,815 - INFO -   score=0.0000
2025-12-19 12:31:09,815 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:09,839 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,840 - INFO -   score=0.0000
2025-12-19 12:31:09,840 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:09,864 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,865 - INFO -   score=0.0000
2025-12-19 12:31:09,865 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:09,904 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,905 - INFO -   score=0.0000
2025-12-19 12:31:09,905 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:09,946 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,947 - INFO -   score=0.0000
2025-12-19 12:31:09,947 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:09,971 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,972 - INFO -   score=0.0000
2025-12-19 12:31:09,972 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:09,996 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:09,997 - INFO -   score=0.0000
2025-12-19 12:31:09,997 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:10,021 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,022 - INFO -   score=0.0000
2025-12-19 12:31:10,022 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:10,047 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,048 - INFO -   score=0.0000
2025-12-19 12:31:10,048 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:10,072 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,073 - INFO -   score=0.0000
2025-12-19 12:31:10,073 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:10,097 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,098 - INFO -   score=0.0000
2025-12-19 12:31:10,098 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:10,138 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,139 - INFO -   score=0.0000
2025-12-19 12:31:10,139 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:10,178 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,179 - INFO -   score=0.0000
2025-12-19 12:31:10,179 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:10,203 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,204 - INFO -   score=0.0000
2025-12-19 12:31:10,204 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:10,228 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,229 - INFO -   score=0.0000
2025-12-19 12:31:10,229 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:10,269 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,270 - INFO -   score=0.0000
2025-12-19 12:31:10,270 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:10,308 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,310 - INFO -   score=0.0000
2025-12-19 12:31:10,310 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:10,334 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,335 - INFO -   score=0.0000
2025-12-19 12:31:10,335 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:10,358 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,359 - INFO -   score=0.0000
2025-12-19 12:31:10,359 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:10,383 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,384 - INFO -   score=0.0000
2025-12-19 12:31:10,384 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:10,408 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,409 - INFO -   score=0.0000
2025-12-19 12:31:10,409 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:10,433 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,434 - INFO -   score=0.0000
2025-12-19 12:31:10,434 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:10,458 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,459 - INFO -   score=0.0000
2025-12-19 12:31:10,459 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:10,498 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,500 - INFO -   score=0.0000
2025-12-19 12:31:10,500 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:10,538 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,540 - INFO -   score=0.0000
2025-12-19 12:31:10,540 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:10,564 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,565 - INFO -   score=0.0000
2025-12-19 12:31:10,565 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:10,589 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,590 - INFO -   score=0.0000
2025-12-19 12:31:10,590 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:10,630 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,631 - INFO -   score=0.0000
2025-12-19 12:31:10,631 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:10,670 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,672 - INFO -   score=0.0000
2025-12-19 12:31:10,672 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:10,695 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,696 - INFO -   score=0.0000
2025-12-19 12:31:10,696 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:10,720 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,721 - INFO -   score=0.0000
2025-12-19 12:31:10,721 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:10,745 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,746 - INFO -   score=0.0000
2025-12-19 12:31:10,746 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:10,770 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,771 - INFO -   score=0.0000
2025-12-19 12:31:10,771 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:10,794 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,796 - INFO -   score=0.0000
2025-12-19 12:31:10,796 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:10,819 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,820 - INFO -   score=0.0000
2025-12-19 12:31:10,820 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:10,862 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,863 - INFO -   score=0.0000
2025-12-19 12:31:10,863 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:10,901 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,903 - INFO -   score=0.0000
2025-12-19 12:31:10,903 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:10,926 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,927 - INFO -   score=0.0000
2025-12-19 12:31:10,927 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:10,951 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,952 - INFO -   score=0.0000
2025-12-19 12:31:10,952 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:10,991 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:10,992 - INFO -   score=0.0000
2025-12-19 12:31:10,992 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:11,033 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,034 - INFO -   score=0.0000
2025-12-19 12:31:11,034 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:11,058 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,060 - INFO -   score=0.0000
2025-12-19 12:31:11,060 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:11,084 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,085 - INFO -   score=0.0000
2025-12-19 12:31:11,085 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:11,108 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,109 - INFO -   score=0.0000
2025-12-19 12:31:11,109 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:11,133 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,134 - INFO -   score=0.0000
2025-12-19 12:31:11,134 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:11,158 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,159 - INFO -   score=0.0000
2025-12-19 12:31:11,159 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:11,182 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,184 - INFO -   score=0.0000
2025-12-19 12:31:11,184 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:11,223 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,224 - INFO -   score=0.0000
2025-12-19 12:31:11,224 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:11,264 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,265 - INFO -   score=0.0000
2025-12-19 12:31:11,265 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:11,289 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,290 - INFO -   score=0.0000
2025-12-19 12:31:11,291 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:11,314 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,315 - INFO -   score=0.0000
2025-12-19 12:31:11,316 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:11,354 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,356 - INFO -   score=0.0000
2025-12-19 12:31:11,356 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:11,395 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,396 - INFO -   score=0.0000
2025-12-19 12:31:11,396 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:11,420 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,421 - INFO -   score=0.0000
2025-12-19 12:31:11,422 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:11,446 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,447 - INFO -   score=0.0000
2025-12-19 12:31:11,447 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:11,470 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,472 - INFO -   score=0.0000
2025-12-19 12:31:11,472 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:11,495 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,496 - INFO -   score=0.0000
2025-12-19 12:31:11,496 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:11,520 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,521 - INFO -   score=0.0000
2025-12-19 12:31:11,521 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:11,545 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,546 - INFO -   score=0.0000
2025-12-19 12:31:11,546 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:11,585 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,586 - INFO -   score=0.0000
2025-12-19 12:31:11,586 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:11,626 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,627 - INFO -   score=0.0000
2025-12-19 12:31:11,627 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:11,651 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,652 - INFO -   score=0.0000
2025-12-19 12:31:11,652 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:11,676 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,677 - INFO -   score=0.0000
2025-12-19 12:31:11,677 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:11,716 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,717 - INFO -   score=0.0000
2025-12-19 12:31:11,717 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:11,757 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,758 - INFO -   score=0.0000
2025-12-19 12:31:11,758 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:11,782 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,783 - INFO -   score=0.0000
2025-12-19 12:31:11,783 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:11,806 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,807 - INFO -   score=0.0000
2025-12-19 12:31:11,808 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:11,831 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,832 - INFO -   score=0.0000
2025-12-19 12:31:11,832 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:11,856 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,857 - INFO -   score=0.0000
2025-12-19 12:31:11,857 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:11,880 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,881 - INFO -   score=0.0000
2025-12-19 12:31:11,881 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:11,905 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,906 - INFO -   score=0.0000
2025-12-19 12:31:11,906 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:11,945 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,946 - INFO -   score=0.0000
2025-12-19 12:31:11,946 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:11,985 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:11,986 - INFO -   score=0.0000
2025-12-19 12:31:11,986 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:12,010 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,011 - INFO -   score=0.0000
2025-12-19 12:31:12,011 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:12,035 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,036 - INFO -   score=0.0000
2025-12-19 12:31:12,036 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:12,075 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,076 - INFO -   score=0.0000
2025-12-19 12:31:12,076 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:12,114 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,115 - INFO -   score=0.0000
2025-12-19 12:31:12,116 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:12,140 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,141 - INFO -   score=0.0000
2025-12-19 12:31:12,141 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:12,165 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,166 - INFO -   score=0.0000
2025-12-19 12:31:12,166 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:12,190 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,191 - INFO -   score=0.0000
2025-12-19 12:31:12,191 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:12,215 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,216 - INFO -   score=0.0000
2025-12-19 12:31:12,216 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:12,240 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,241 - INFO -   score=0.0000
2025-12-19 12:31:12,241 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:12,264 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,265 - INFO -   score=0.0000
2025-12-19 12:31:12,266 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:12,304 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,305 - INFO -   score=0.0000
2025-12-19 12:31:12,306 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:12,344 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,345 - INFO -   score=0.0000
2025-12-19 12:31:12,346 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:12,369 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,371 - INFO -   score=0.0000
2025-12-19 12:31:12,371 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:12,394 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,395 - INFO -   score=0.0000
2025-12-19 12:31:12,395 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:12,435 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,436 - INFO -   score=0.0000
2025-12-19 12:31:12,436 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:12,475 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,476 - INFO -   score=0.0000
2025-12-19 12:31:12,476 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:12,500 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,501 - INFO -   score=0.0000
2025-12-19 12:31:12,501 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:12,525 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,526 - INFO -   score=0.0000
2025-12-19 12:31:12,526 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:12,549 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,550 - INFO -   score=0.0000
2025-12-19 12:31:12,550 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:12,574 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,575 - INFO -   score=0.0000
2025-12-19 12:31:12,575 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:12,599 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,600 - INFO -   score=0.0000
2025-12-19 12:31:12,601 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:12,624 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,625 - INFO -   score=0.0000
2025-12-19 12:31:12,625 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:12,665 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,667 - INFO -   score=0.0000
2025-12-19 12:31:12,667 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:12,706 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,707 - INFO -   score=0.0000
2025-12-19 12:31:12,707 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:12,731 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,732 - INFO -   score=0.0000
2025-12-19 12:31:12,732 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:12,756 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,757 - INFO -   score=0.0000
2025-12-19 12:31:12,757 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:12,796 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,797 - INFO -   score=0.0000
2025-12-19 12:31:12,797 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:12,836 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,837 - INFO -   score=0.0000
2025-12-19 12:31:12,837 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:12,862 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,863 - INFO -   score=0.0000
2025-12-19 12:31:12,863 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:12,886 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,887 - INFO -   score=0.0000
2025-12-19 12:31:12,887 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:12,911 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,912 - INFO -   score=0.0000
2025-12-19 12:31:12,912 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:12,936 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,937 - INFO -   score=0.0000
2025-12-19 12:31:12,937 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:12,960 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,961 - INFO -   score=0.0000
2025-12-19 12:31:12,961 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:12,985 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:12,986 - INFO -   score=0.0000
2025-12-19 12:31:12,987 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:13,028 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,030 - INFO -   score=0.0000
2025-12-19 12:31:13,030 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:13,067 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,069 - INFO -   score=0.0000
2025-12-19 12:31:13,069 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:13,093 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,094 - INFO -   score=0.0000
2025-12-19 12:31:13,094 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:13,118 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,119 - INFO -   score=0.0000
2025-12-19 12:31:13,119 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:13,161 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,162 - INFO -   score=0.0000
2025-12-19 12:31:13,162 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:31:13,201 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,203 - INFO -   score=0.0000
2025-12-19 12:31:13,205 - INFO - 
--- Tuning LGSTM ---
2025-12-19 12:31:13,205 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:13,230 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,231 - INFO -   score=0.0000
2025-12-19 12:31:13,231 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:13,256 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,257 - INFO -   score=0.0000
2025-12-19 12:31:13,257 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:13,282 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,283 - INFO -   score=0.0000
2025-12-19 12:31:13,283 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:13,308 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,309 - INFO -   score=0.0000
2025-12-19 12:31:13,309 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:13,334 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,335 - INFO -   score=0.0000
2025-12-19 12:31:13,335 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:13,359 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,360 - INFO -   score=0.0000
2025-12-19 12:31:13,360 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:13,385 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,386 - INFO -   score=0.0000
2025-12-19 12:31:13,386 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:13,411 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,412 - INFO -   score=0.0000
2025-12-19 12:31:13,412 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:13,436 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,438 - INFO -   score=0.0000
2025-12-19 12:31:13,438 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:13,462 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,463 - INFO -   score=0.0000
2025-12-19 12:31:13,463 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:13,488 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,489 - INFO -   score=0.0000
2025-12-19 12:31:13,489 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:13,514 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,515 - INFO -   score=0.0000
2025-12-19 12:31:13,515 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:13,540 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,541 - INFO -   score=0.0000
2025-12-19 12:31:13,541 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:13,566 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,567 - INFO -   score=0.0000
2025-12-19 12:31:13,567 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:13,592 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,593 - INFO -   score=0.0000
2025-12-19 12:31:13,593 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:13,618 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,619 - INFO -   score=0.0000
2025-12-19 12:31:13,619 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:13,644 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,645 - INFO -   score=0.0000
2025-12-19 12:31:13,645 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:13,669 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,671 - INFO -   score=0.0000
2025-12-19 12:31:13,671 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:13,695 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,697 - INFO -   score=0.0000
2025-12-19 12:31:13,697 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:13,722 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,723 - INFO -   score=0.0000
2025-12-19 12:31:13,723 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:13,747 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,748 - INFO -   score=0.0000
2025-12-19 12:31:13,748 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:13,773 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,774 - INFO -   score=0.0000
2025-12-19 12:31:13,774 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:13,799 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,800 - INFO -   score=0.0000
2025-12-19 12:31:13,800 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:13,825 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,826 - INFO -   score=0.0000
2025-12-19 12:31:13,826 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:13,869 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,870 - INFO -   score=0.0000
2025-12-19 12:31:13,870 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:13,910 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,911 - INFO -   score=0.0000
2025-12-19 12:31:13,911 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:13,952 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,954 - INFO -   score=0.0000
2025-12-19 12:31:13,954 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:13,994 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:13,996 - INFO -   score=0.0000
2025-12-19 12:31:13,996 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:14,037 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,038 - INFO -   score=0.0000
2025-12-19 12:31:14,038 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:14,078 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,080 - INFO -   score=0.0000
2025-12-19 12:31:14,080 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:14,121 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,122 - INFO -   score=0.0000
2025-12-19 12:31:14,122 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:14,163 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,165 - INFO -   score=0.0000
2025-12-19 12:31:14,165 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:14,189 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,190 - INFO -   score=0.0000
2025-12-19 12:31:14,191 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:14,215 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,216 - INFO -   score=0.0000
2025-12-19 12:31:14,216 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:14,241 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,243 - INFO -   score=0.0000
2025-12-19 12:31:14,243 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:14,268 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,269 - INFO -   score=0.0000
2025-12-19 12:31:14,269 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:14,294 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,295 - INFO -   score=0.0000
2025-12-19 12:31:14,295 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:14,319 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,320 - INFO -   score=0.0000
2025-12-19 12:31:14,320 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:14,345 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,346 - INFO -   score=0.0000
2025-12-19 12:31:14,346 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:14,371 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,372 - INFO -   score=0.0000
2025-12-19 12:31:14,372 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:14,414 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,416 - INFO -   score=0.0000
2025-12-19 12:31:14,416 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:14,455 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,457 - INFO -   score=0.0000
2025-12-19 12:31:14,457 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:14,498 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,499 - INFO -   score=0.0000
2025-12-19 12:31:14,499 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:14,540 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,541 - INFO -   score=0.0000
2025-12-19 12:31:14,541 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:14,581 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,583 - INFO -   score=0.0000
2025-12-19 12:31:14,583 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:14,624 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,625 - INFO -   score=0.0000
2025-12-19 12:31:14,625 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:14,666 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,668 - INFO -   score=0.0000
2025-12-19 12:31:14,668 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:14,710 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,711 - INFO -   score=0.0000
2025-12-19 12:31:14,711 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:14,736 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,737 - INFO -   score=0.0000
2025-12-19 12:31:14,737 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:14,762 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,764 - INFO -   score=0.0000
2025-12-19 12:31:14,764 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:14,789 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,790 - INFO -   score=0.0000
2025-12-19 12:31:14,790 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:14,815 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,816 - INFO -   score=0.0000
2025-12-19 12:31:14,816 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:14,841 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,842 - INFO -   score=0.0000
2025-12-19 12:31:14,842 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:14,867 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,868 - INFO -   score=0.0000
2025-12-19 12:31:14,868 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:14,893 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,894 - INFO -   score=0.0000
2025-12-19 12:31:14,894 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:14,919 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,920 - INFO -   score=0.0000
2025-12-19 12:31:14,920 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:14,944 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,946 - INFO -   score=0.0000
2025-12-19 12:31:14,946 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:14,970 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,971 - INFO -   score=0.0000
2025-12-19 12:31:14,971 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:14,996 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:14,997 - INFO -   score=0.0000
2025-12-19 12:31:14,997 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:15,022 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,023 - INFO -   score=0.0000
2025-12-19 12:31:15,023 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:15,047 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,049 - INFO -   score=0.0000
2025-12-19 12:31:15,049 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:15,073 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,074 - INFO -   score=0.0000
2025-12-19 12:31:15,074 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:15,099 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,100 - INFO -   score=0.0000
2025-12-19 12:31:15,100 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:15,125 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,126 - INFO -   score=0.0000
2025-12-19 12:31:15,126 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:15,151 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,152 - INFO -   score=0.0000
2025-12-19 12:31:15,152 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:15,176 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,177 - INFO -   score=0.0000
2025-12-19 12:31:15,177 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:15,202 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,203 - INFO -   score=0.0000
2025-12-19 12:31:15,203 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:15,229 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,230 - INFO -   score=0.0000
2025-12-19 12:31:15,230 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:15,254 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,255 - INFO -   score=0.0000
2025-12-19 12:31:15,255 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:15,280 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,281 - INFO -   score=0.0000
2025-12-19 12:31:15,281 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:15,306 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,307 - INFO -   score=0.0000
2025-12-19 12:31:15,307 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:15,332 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,333 - INFO -   score=0.0000
2025-12-19 12:31:15,333 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:15,377 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,378 - INFO -   score=0.0000
2025-12-19 12:31:15,379 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:15,418 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,420 - INFO -   score=0.0000
2025-12-19 12:31:15,420 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:15,460 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,462 - INFO -   score=0.0000
2025-12-19 12:31:15,462 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:15,503 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,504 - INFO -   score=0.0000
2025-12-19 12:31:15,504 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:15,546 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,548 - INFO -   score=0.0000
2025-12-19 12:31:15,548 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:15,588 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,589 - INFO -   score=0.0000
2025-12-19 12:31:15,590 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:15,631 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,632 - INFO -   score=0.0000
2025-12-19 12:31:15,632 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:15,674 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,676 - INFO -   score=0.0000
2025-12-19 12:31:15,676 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:15,701 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,702 - INFO -   score=0.0000
2025-12-19 12:31:15,702 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:15,727 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,728 - INFO -   score=0.0000
2025-12-19 12:31:15,728 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:15,753 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,754 - INFO -   score=0.0000
2025-12-19 12:31:15,754 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:15,779 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,780 - INFO -   score=0.0000
2025-12-19 12:31:15,780 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:15,804 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,806 - INFO -   score=0.0000
2025-12-19 12:31:15,806 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:15,830 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,831 - INFO -   score=0.0000
2025-12-19 12:31:15,831 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:15,856 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,857 - INFO -   score=0.0000
2025-12-19 12:31:15,857 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:15,882 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,883 - INFO -   score=0.0000
2025-12-19 12:31:15,883 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:15,926 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,927 - INFO -   score=0.0000
2025-12-19 12:31:15,927 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:15,966 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:15,967 - INFO -   score=0.0000
2025-12-19 12:31:15,967 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:16,008 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,010 - INFO -   score=0.0000
2025-12-19 12:31:16,010 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:16,051 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,053 - INFO -   score=0.0000
2025-12-19 12:31:16,053 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:16,093 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,095 - INFO -   score=0.0000
2025-12-19 12:31:16,095 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:16,137 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,138 - INFO -   score=0.0000
2025-12-19 12:31:16,138 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:16,178 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,180 - INFO -   score=0.0000
2025-12-19 12:31:16,180 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:16,221 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,223 - INFO -   score=0.0000
2025-12-19 12:31:16,223 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:16,248 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,249 - INFO -   score=0.0000
2025-12-19 12:31:16,249 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:16,273 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,274 - INFO -   score=0.0000
2025-12-19 12:31:16,274 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:16,299 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,300 - INFO -   score=0.0000
2025-12-19 12:31:16,300 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:16,325 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,326 - INFO -   score=0.0000
2025-12-19 12:31:16,326 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:16,350 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,351 - INFO -   score=0.0000
2025-12-19 12:31:16,351 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:16,376 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,377 - INFO -   score=0.0000
2025-12-19 12:31:16,377 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:16,402 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,403 - INFO -   score=0.0000
2025-12-19 12:31:16,403 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:16,428 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,429 - INFO -   score=0.0000
2025-12-19 12:31:16,429 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:16,454 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,456 - INFO -   score=0.0000
2025-12-19 12:31:16,456 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:16,480 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,481 - INFO -   score=0.0000
2025-12-19 12:31:16,482 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:16,506 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,508 - INFO -   score=0.0000
2025-12-19 12:31:16,508 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:16,532 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,534 - INFO -   score=0.0000
2025-12-19 12:31:16,534 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:16,558 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,559 - INFO -   score=0.0000
2025-12-19 12:31:16,559 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:16,584 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,585 - INFO -   score=0.0000
2025-12-19 12:31:16,585 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:16,610 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,611 - INFO -   score=0.0000
2025-12-19 12:31:16,611 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:16,636 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,637 - INFO -   score=0.0000
2025-12-19 12:31:16,637 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:16,662 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,663 - INFO -   score=0.0000
2025-12-19 12:31:16,663 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:16,687 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,688 - INFO -   score=0.0000
2025-12-19 12:31:16,688 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:16,713 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,714 - INFO -   score=0.0000
2025-12-19 12:31:16,714 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:16,739 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,740 - INFO -   score=0.0000
2025-12-19 12:31:16,740 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:16,764 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,765 - INFO -   score=0.0000
2025-12-19 12:31:16,765 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:16,790 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,791 - INFO -   score=0.0000
2025-12-19 12:31:16,791 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:16,816 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,817 - INFO -   score=0.0000
2025-12-19 12:31:16,817 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:16,842 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,843 - INFO -   score=0.0000
2025-12-19 12:31:16,843 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:16,886 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,887 - INFO -   score=0.0000
2025-12-19 12:31:16,887 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:16,926 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,927 - INFO -   score=0.0000
2025-12-19 12:31:16,927 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:16,969 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:16,970 - INFO -   score=0.0000
2025-12-19 12:31:16,970 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:17,012 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,014 - INFO -   score=0.0000
2025-12-19 12:31:17,014 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:17,056 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,057 - INFO -   score=0.0000
2025-12-19 12:31:17,057 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:17,098 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,099 - INFO -   score=0.0000
2025-12-19 12:31:17,099 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:17,140 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,141 - INFO -   score=0.0000
2025-12-19 12:31:17,141 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:17,183 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,185 - INFO -   score=0.0000
2025-12-19 12:31:17,185 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:17,210 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,211 - INFO -   score=0.0000
2025-12-19 12:31:17,211 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:17,236 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,237 - INFO -   score=0.0000
2025-12-19 12:31:17,237 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:17,263 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,264 - INFO -   score=0.0000
2025-12-19 12:31:17,264 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:17,289 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,290 - INFO -   score=0.0000
2025-12-19 12:31:17,290 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:17,315 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,316 - INFO -   score=0.0000
2025-12-19 12:31:17,316 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:17,341 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,342 - INFO -   score=0.0000
2025-12-19 12:31:17,342 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:17,366 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,368 - INFO -   score=0.0000
2025-12-19 12:31:17,368 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:17,393 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,394 - INFO -   score=0.0000
2025-12-19 12:31:17,394 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:17,435 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,436 - INFO -   score=0.0000
2025-12-19 12:31:17,436 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:17,477 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,478 - INFO -   score=0.0000
2025-12-19 12:31:17,478 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:17,519 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,521 - INFO -   score=0.0000
2025-12-19 12:31:17,521 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:17,563 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,564 - INFO -   score=0.0000
2025-12-19 12:31:17,564 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:17,605 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,606 - INFO -   score=0.0000
2025-12-19 12:31:17,606 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:17,648 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,649 - INFO -   score=0.0000
2025-12-19 12:31:17,649 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:17,690 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,692 - INFO -   score=0.0000
2025-12-19 12:31:17,692 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:17,733 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,734 - INFO -   score=0.0000
2025-12-19 12:31:17,734 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:17,759 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,760 - INFO -   score=0.0000
2025-12-19 12:31:17,760 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:17,785 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,786 - INFO -   score=0.0000
2025-12-19 12:31:17,786 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:17,811 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,812 - INFO -   score=0.0000
2025-12-19 12:31:17,812 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:17,837 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,838 - INFO -   score=0.0000
2025-12-19 12:31:17,839 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:17,863 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,864 - INFO -   score=0.0000
2025-12-19 12:31:17,864 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:17,889 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,890 - INFO -   score=0.0000
2025-12-19 12:31:17,890 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:17,915 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,916 - INFO -   score=0.0000
2025-12-19 12:31:17,916 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:17,941 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,942 - INFO -   score=0.0000
2025-12-19 12:31:17,942 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:17,966 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,968 - INFO -   score=0.0000
2025-12-19 12:31:17,968 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:17,992 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:17,993 - INFO -   score=0.0000
2025-12-19 12:31:17,993 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:18,018 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,019 - INFO -   score=0.0000
2025-12-19 12:31:18,019 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:18,044 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,045 - INFO -   score=0.0000
2025-12-19 12:31:18,045 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:18,070 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,071 - INFO -   score=0.0000
2025-12-19 12:31:18,071 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:18,096 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,097 - INFO -   score=0.0000
2025-12-19 12:31:18,097 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:18,122 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,124 - INFO -   score=0.0000
2025-12-19 12:31:18,124 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:18,149 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,150 - INFO -   score=0.0000
2025-12-19 12:31:18,150 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:18,175 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,176 - INFO -   score=0.0000
2025-12-19 12:31:18,176 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:18,201 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,202 - INFO -   score=0.0000
2025-12-19 12:31:18,202 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:18,227 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,228 - INFO -   score=0.0000
2025-12-19 12:31:18,228 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:18,254 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,255 - INFO -   score=0.0000
2025-12-19 12:31:18,255 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:18,279 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,281 - INFO -   score=0.0000
2025-12-19 12:31:18,281 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:18,305 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,306 - INFO -   score=0.0000
2025-12-19 12:31:18,307 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:18,331 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,333 - INFO -   score=0.0000
2025-12-19 12:31:18,333 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:18,357 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,359 - INFO -   score=0.0000
2025-12-19 12:31:18,359 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:18,402 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,403 - INFO -   score=0.0000
2025-12-19 12:31:18,404 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:18,443 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,445 - INFO -   score=0.0000
2025-12-19 12:31:18,445 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:18,485 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,487 - INFO -   score=0.0000
2025-12-19 12:31:18,487 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:18,528 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,529 - INFO -   score=0.0000
2025-12-19 12:31:18,529 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:18,571 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,572 - INFO -   score=0.0000
2025-12-19 12:31:18,572 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:18,612 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,613 - INFO -   score=0.0000
2025-12-19 12:31:18,613 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:18,656 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,658 - INFO -   score=0.0000
2025-12-19 12:31:18,658 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:18,698 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,699 - INFO -   score=0.0000
2025-12-19 12:31:18,699 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:18,724 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,725 - INFO -   score=0.0000
2025-12-19 12:31:18,725 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:18,750 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,751 - INFO -   score=0.0000
2025-12-19 12:31:18,751 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:18,776 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,777 - INFO -   score=0.0000
2025-12-19 12:31:18,777 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:18,802 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,803 - INFO -   score=0.0000
2025-12-19 12:31:18,803 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:18,828 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,829 - INFO -   score=0.0000
2025-12-19 12:31:18,829 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:18,853 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,854 - INFO -   score=0.0000
2025-12-19 12:31:18,854 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:18,879 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,880 - INFO -   score=0.0000
2025-12-19 12:31:18,880 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:18,905 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,906 - INFO -   score=0.0000
2025-12-19 12:31:18,906 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:18,949 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,950 - INFO -   score=0.0000
2025-12-19 12:31:18,950 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:18,990 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:18,991 - INFO -   score=0.0000
2025-12-19 12:31:18,991 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:19,032 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:19,033 - INFO -   score=0.0000
2025-12-19 12:31:19,033 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:19,075 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:19,076 - INFO -   score=0.0000
2025-12-19 12:31:19,076 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:31:19,117 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:19,119 - INFO -   score=0.0000
2025-12-19 12:31:19,119 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:31:19,161 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:19,163 - INFO -   score=0.0000
2025-12-19 12:31:19,163 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:31:19,204 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:19,205 - INFO -   score=0.0000
2025-12-19 12:31:19,205 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:31:19,247 - INFO -   fit failed: [Errno 24] Too many open files
2025-12-19 12:31:19,248 - INFO -   score=0.0000
2025-12-19 12:31:19,250 - INFO - 
✓ Overall Best Model: CNN (score=0.9898)
2025-12-19 12:31:19,250 - INFO -   Best Config: {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:31:19,250 - INFO - 
=== FINAL EXPERIMENTS ===

2025-12-19 12:31:19,250 - INFO - Training CNN for 10 epochs...
2025-12-19 12:41:36,652 - INFO - Using device: cuda
2025-12-19 12:41:36,652 - INFO - Loading preprocessed data from preprocessed_data.pkl...
2025-12-19 12:41:37,080 - INFO - ✓ Data loaded from cache.
2025-12-19 12:41:37,080 - INFO - Train: torch.Size([32268, 256, 41]), Val: torch.Size([4033, 256, 41]), Test: torch.Size([4035, 256, 41])
2025-12-19 12:41:37,080 - INFO - === FULL GRID SEARCH ON ALL MODELS (PYTORCH) ===

2025-12-19 12:41:37,080 - INFO - --- Tuning RNN ---
2025-12-19 12:41:37,080 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:41:41,214 - INFO -   score=0.9866
2025-12-19 12:41:41,215 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:41:44,742 - INFO -   score=0.9881
2025-12-19 12:41:44,742 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:41:48,242 - INFO -   score=0.9489
2025-12-19 12:41:48,242 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:41:51,764 - INFO -   score=0.9561
2025-12-19 12:41:51,764 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:41:55,224 - INFO -   score=0.9287
2025-12-19 12:41:55,224 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:41:58,708 - INFO -   score=0.9085
2025-12-19 12:41:58,708 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:42:02,134 - INFO -   score=0.9548
2025-12-19 12:42:02,134 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:42:05,620 - INFO -   score=0.9587
2025-12-19 12:42:05,620 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:42:09,097 - INFO -   score=0.9783
2025-12-19 12:42:09,097 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:42:12,601 - INFO -   score=0.9809
2025-12-19 12:42:12,601 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:42:16,085 - INFO -   score=0.9555
2025-12-19 12:42:16,085 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:42:19,618 - INFO -   score=0.9801
2025-12-19 12:42:19,618 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:42:23,238 - INFO -   score=0.9329
2025-12-19 12:42:23,238 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:42:26,893 - INFO -   score=0.9316
2025-12-19 12:42:26,893 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:42:30,501 - INFO -   score=0.9576
2025-12-19 12:42:30,501 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:42:34,118 - INFO -   score=0.9560
2025-12-19 12:42:34,118 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:42:37,539 - INFO -   score=0.6703
2025-12-19 12:42:37,539 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:42:40,936 - INFO -   score=0.6741
2025-12-19 12:42:40,936 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:42:44,373 - INFO -   score=0.6488
2025-12-19 12:42:44,373 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:42:47,818 - INFO -   score=0.6506
2025-12-19 12:42:47,819 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:42:51,361 - INFO -   score=0.5022
2025-12-19 12:42:51,361 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:42:54,908 - INFO -   score=0.5020
2025-12-19 12:42:54,908 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:42:58,442 - INFO -   score=0.5023
2025-12-19 12:42:58,442 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:43:02,008 - INFO -   score=0.5018
2025-12-19 12:43:02,008 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:43:05,493 - INFO -   score=0.9868
2025-12-19 12:43:05,493 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:43:09,003 - INFO -   score=0.9872
2025-12-19 12:43:09,003 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:43:12,482 - INFO -   score=0.9521
2025-12-19 12:43:12,482 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:43:16,019 - INFO -   score=0.9590
2025-12-19 12:43:16,019 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:43:19,483 - INFO -   score=0.9339
2025-12-19 12:43:19,483 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:43:22,965 - INFO -   score=0.9125
2025-12-19 12:43:22,965 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:43:26,449 - INFO -   score=0.9534
2025-12-19 12:43:26,449 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:43:30,000 - INFO -   score=0.9558
2025-12-19 12:43:30,000 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:43:33,490 - INFO -   score=0.9839
2025-12-19 12:43:33,491 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:43:37,001 - INFO -   score=0.9743
2025-12-19 12:43:37,001 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:43:40,468 - INFO -   score=0.9739
2025-12-19 12:43:40,468 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:43:43,978 - INFO -   score=0.9741
2025-12-19 12:43:43,978 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:43:47,555 - INFO -   score=0.9380
2025-12-19 12:43:47,556 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:43:51,167 - INFO -   score=0.9360
2025-12-19 12:43:51,167 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:43:54,764 - INFO -   score=0.9637
2025-12-19 12:43:54,764 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:43:58,374 - INFO -   score=0.9549
2025-12-19 12:43:58,374 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:44:01,783 - INFO -   score=0.6531
2025-12-19 12:44:01,783 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:44:05,226 - INFO -   score=0.7084
2025-12-19 12:44:05,226 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:44:09,274 - INFO -   score=0.6257
2025-12-19 12:44:09,274 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:44:12,718 - INFO -   score=0.6460
2025-12-19 12:44:12,718 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:44:16,248 - INFO -   score=0.5020
2025-12-19 12:44:16,248 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:44:19,821 - INFO -   score=0.5000
2025-12-19 12:44:19,821 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:44:23,345 - INFO -   score=0.5022
2025-12-19 12:44:23,345 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:44:26,887 - INFO -   score=0.5007
2025-12-19 12:44:26,887 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:44:29,105 - INFO -   score=0.9238
2025-12-19 12:44:29,105 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:44:31,377 - INFO -   score=0.9843
2025-12-19 12:44:31,377 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:44:33,611 - INFO -   score=0.9511
2025-12-19 12:44:33,611 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:44:35,871 - INFO -   score=0.9558
2025-12-19 12:44:35,871 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:44:38,082 - INFO -   score=0.9463
2025-12-19 12:44:38,082 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:44:40,326 - INFO -   score=0.9281
2025-12-19 12:44:40,326 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:44:42,534 - INFO -   score=0.9585
2025-12-19 12:44:42,534 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:44:44,739 - INFO -   score=0.9578
2025-12-19 12:44:44,739 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:44:46,972 - INFO -   score=0.9703
2025-12-19 12:44:46,972 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:44:49,242 - INFO -   score=0.9736
2025-12-19 12:44:49,243 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:44:51,472 - INFO -   score=0.9122
2025-12-19 12:44:51,473 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:44:53,720 - INFO -   score=0.9665
2025-12-19 12:44:53,720 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:44:56,003 - INFO -   score=0.9448
2025-12-19 12:44:56,003 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:44:58,289 - INFO -   score=0.9451
2025-12-19 12:44:58,289 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:45:00,588 - INFO -   score=0.9566
2025-12-19 12:45:00,588 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:45:02,888 - INFO -   score=0.9601
2025-12-19 12:45:02,888 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:45:05,005 - INFO -   score=0.6601
2025-12-19 12:45:05,005 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:45:07,186 - INFO -   score=0.7164
2025-12-19 12:45:07,186 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:45:09,327 - INFO -   score=0.6282
2025-12-19 12:45:09,328 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:45:11,514 - INFO -   score=0.6435
2025-12-19 12:45:11,514 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:45:13,738 - INFO -   score=0.5208
2025-12-19 12:45:13,738 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:45:15,960 - INFO -   score=0.5046
2025-12-19 12:45:15,960 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:45:18,198 - INFO -   score=0.5055
2025-12-19 12:45:18,199 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:45:20,441 - INFO -   score=0.5002
2025-12-19 12:45:20,441 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:45:22,663 - INFO -   score=0.9781
2025-12-19 12:45:22,663 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:45:24,920 - INFO -   score=0.9836
2025-12-19 12:45:24,920 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:45:27,171 - INFO -   score=0.9533
2025-12-19 12:45:27,171 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:45:29,445 - INFO -   score=0.9564
2025-12-19 12:45:29,445 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:45:31,644 - INFO -   score=0.9384
2025-12-19 12:45:31,644 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:45:33,873 - INFO -   score=0.9290
2025-12-19 12:45:33,873 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:45:36,088 - INFO -   score=0.9591
2025-12-19 12:45:36,088 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:45:38,322 - INFO -   score=0.9548
2025-12-19 12:45:38,322 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:45:40,549 - INFO -   score=0.9751
2025-12-19 12:45:40,549 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:45:42,825 - INFO -   score=0.9817
2025-12-19 12:45:42,825 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:45:45,045 - INFO -   score=0.9280
2025-12-19 12:45:45,046 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:45:47,318 - INFO -   score=0.9721
2025-12-19 12:45:47,318 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:45:49,574 - INFO -   score=0.9370
2025-12-19 12:45:49,574 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:45:51,870 - INFO -   score=0.9396
2025-12-19 12:45:51,870 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:45:54,166 - INFO -   score=0.9585
2025-12-19 12:45:54,166 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:45:56,477 - INFO -   score=0.9633
2025-12-19 12:45:56,477 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:45:58,616 - INFO -   score=0.6764
2025-12-19 12:45:58,616 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:46:00,779 - INFO -   score=0.7222
2025-12-19 12:46:00,779 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:46:02,917 - INFO -   score=0.6187
2025-12-19 12:46:02,917 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:46:05,111 - INFO -   score=0.6366
2025-12-19 12:46:05,111 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:46:07,317 - INFO -   score=0.5032
2025-12-19 12:46:07,317 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:46:09,550 - INFO -   score=0.5038
2025-12-19 12:46:09,550 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 64}
2025-12-19 12:46:11,784 - INFO -   score=0.5014
2025-12-19 12:46:11,785 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'units': 128}
2025-12-19 12:46:14,019 - INFO -   score=0.5004
2025-12-19 12:46:14,020 - INFO - 
--- Tuning CNN ---
2025-12-19 12:46:14,020 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:46:17,368 - INFO -   score=0.9879
2025-12-19 12:46:17,369 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:46:20,639 - INFO -   score=0.8366
2025-12-19 12:46:20,639 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:46:23,882 - INFO -   score=0.2090
2025-12-19 12:46:23,882 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:46:27,120 - INFO -   score=0.0670
2025-12-19 12:46:27,120 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:46:30,374 - INFO -   score=0.9790
2025-12-19 12:46:30,374 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:46:33,631 - INFO -   score=0.9284
2025-12-19 12:46:33,631 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:46:36,979 - INFO -   score=0.0788
2025-12-19 12:46:36,979 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:46:40,434 - INFO -   score=0.0724
2025-12-19 12:46:40,434 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:46:43,787 - INFO -   score=0.9186
2025-12-19 12:46:43,787 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:46:47,098 - INFO -   score=0.8454
2025-12-19 12:46:47,098 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:46:50,517 - INFO -   score=0.5000
2025-12-19 12:46:50,517 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:46:53,904 - INFO -   score=0.5000
2025-12-19 12:46:53,904 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:46:57,377 - INFO -   score=0.9885
2025-12-19 12:46:57,378 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:47:00,763 - INFO -   score=0.9014
2025-12-19 12:47:00,763 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:47:04,268 - INFO -   score=0.0745
2025-12-19 12:47:04,268 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:47:07,573 - INFO -   score=0.0716
2025-12-19 12:47:07,573 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:47:10,904 - INFO -   score=0.9842
2025-12-19 12:47:10,904 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:47:14,165 - INFO -   score=0.9661
2025-12-19 12:47:14,166 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:47:17,531 - INFO -   score=0.0778
2025-12-19 12:47:17,531 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:47:20,906 - INFO -   score=0.0757
2025-12-19 12:47:20,906 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:47:24,103 - INFO -   score=0.5000
2025-12-19 12:47:24,103 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:47:27,323 - INFO -   score=0.7881
2025-12-19 12:47:27,323 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:47:30,677 - INFO -   score=0.5000
2025-12-19 12:47:30,677 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:47:34,045 - INFO -   score=0.5000
2025-12-19 12:47:34,045 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:47:37,377 - INFO -   score=0.9888
2025-12-19 12:47:37,378 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:47:40,707 - INFO -   score=0.8705
2025-12-19 12:47:40,707 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:47:44,004 - INFO -   score=0.0724
2025-12-19 12:47:44,004 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:47:47,305 - INFO -   score=0.0708
2025-12-19 12:47:47,305 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:47:50,590 - INFO -   score=0.9840
2025-12-19 12:47:50,590 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:47:53,884 - INFO -   score=0.9574
2025-12-19 12:47:53,884 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:47:57,266 - INFO -   score=0.0780
2025-12-19 12:47:57,266 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:48:00,657 - INFO -   score=0.0789
2025-12-19 12:48:00,657 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:48:03,892 - INFO -   score=0.5000
2025-12-19 12:48:03,892 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:48:07,119 - INFO -   score=0.6332
2025-12-19 12:48:07,119 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:48:10,520 - INFO -   score=0.5000
2025-12-19 12:48:10,520 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:48:13,894 - INFO -   score=0.5000
2025-12-19 12:48:13,894 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:48:17,255 - INFO -   score=0.9894
2025-12-19 12:48:17,256 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:48:20,660 - INFO -   score=0.9395
2025-12-19 12:48:20,660 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:48:24,017 - INFO -   score=0.0642
2025-12-19 12:48:24,017 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:48:27,504 - INFO -   score=0.0713
2025-12-19 12:48:27,505 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:48:31,087 - INFO -   score=0.9863
2025-12-19 12:48:31,087 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:48:34,404 - INFO -   score=0.9725
2025-12-19 12:48:34,405 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:48:37,796 - INFO -   score=0.0783
2025-12-19 12:48:37,796 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:48:41,207 - INFO -   score=0.0786
2025-12-19 12:48:41,207 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:48:44,471 - INFO -   score=0.5000
2025-12-19 12:48:44,471 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:48:47,751 - INFO -   score=0.8230
2025-12-19 12:48:47,751 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:48:51,137 - INFO -   score=0.5000
2025-12-19 12:48:51,137 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:48:54,546 - INFO -   score=0.5000
2025-12-19 12:48:54,546 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:48:57,849 - INFO -   score=0.9879
2025-12-19 12:48:57,849 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:49:01,180 - INFO -   score=0.8304
2025-12-19 12:49:01,180 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:49:04,676 - INFO -   score=0.0870
2025-12-19 12:49:04,676 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:49:07,999 - INFO -   score=0.0729
2025-12-19 12:49:07,999 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:49:11,270 - INFO -   score=0.9506
2025-12-19 12:49:11,270 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:49:14,651 - INFO -   score=0.9269
2025-12-19 12:49:14,651 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:49:18,037 - INFO -   score=0.0782
2025-12-19 12:49:18,038 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:49:21,622 - INFO -   score=0.0763
2025-12-19 12:49:21,622 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:49:24,933 - INFO -   score=0.9284
2025-12-19 12:49:24,933 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:49:28,153 - INFO -   score=0.5691
2025-12-19 12:49:28,153 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:49:31,486 - INFO -   score=0.5000
2025-12-19 12:49:31,486 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:49:34,804 - INFO -   score=0.5000
2025-12-19 12:49:34,804 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:49:38,318 - INFO -   score=0.9881
2025-12-19 12:49:38,319 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:49:41,742 - INFO -   score=0.8601
2025-12-19 12:49:41,742 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:49:45,082 - INFO -   score=0.0663
2025-12-19 12:49:45,082 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:49:48,384 - INFO -   score=0.0651
2025-12-19 12:49:48,384 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:49:51,651 - INFO -   score=0.9780
2025-12-19 12:49:51,651 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:49:54,975 - INFO -   score=0.8680
2025-12-19 12:49:54,975 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:49:58,337 - INFO -   score=0.0863
2025-12-19 12:49:58,337 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:50:01,714 - INFO -   score=0.0782
2025-12-19 12:50:01,714 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:50:04,958 - INFO -   score=0.8633
2025-12-19 12:50:04,958 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:50:08,188 - INFO -   score=0.5007
2025-12-19 12:50:08,189 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:50:11,531 - INFO -   score=0.5000
2025-12-19 12:50:11,531 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:50:14,880 - INFO -   score=0.5000
2025-12-19 12:50:14,881 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:50:18,199 - INFO -   score=0.9889
2025-12-19 12:50:18,199 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:50:21,493 - INFO -   score=0.9072
2025-12-19 12:50:21,493 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:50:24,748 - INFO -   score=0.0769
2025-12-19 12:50:24,748 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:50:28,007 - INFO -   score=0.0657
2025-12-19 12:50:28,007 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:50:31,261 - INFO -   score=0.9825
2025-12-19 12:50:31,261 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:50:34,558 - INFO -   score=0.9194
2025-12-19 12:50:34,558 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:50:37,917 - INFO -   score=0.0778
2025-12-19 12:50:37,917 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:50:41,278 - INFO -   score=0.0788
2025-12-19 12:50:41,278 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:50:44,476 - INFO -   score=0.5000
2025-12-19 12:50:44,476 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:50:47,705 - INFO -   score=0.7366
2025-12-19 12:50:47,705 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:50:51,001 - INFO -   score=0.5000
2025-12-19 12:50:51,001 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:50:54,339 - INFO -   score=0.5000
2025-12-19 12:50:54,339 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:50:57,719 - INFO -   score=0.9890
2025-12-19 12:50:57,719 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:51:01,069 - INFO -   score=0.9117
2025-12-19 12:51:01,069 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:51:04,375 - INFO -   score=0.0595
2025-12-19 12:51:04,375 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:51:07,679 - INFO -   score=0.0716
2025-12-19 12:51:07,679 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:51:10,984 - INFO -   score=0.9877
2025-12-19 12:51:10,984 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:51:14,291 - INFO -   score=0.9324
2025-12-19 12:51:14,291 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:51:17,680 - INFO -   score=0.0779
2025-12-19 12:51:17,680 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:51:21,073 - INFO -   score=0.0790
2025-12-19 12:51:21,073 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:51:24,290 - INFO -   score=0.5000
2025-12-19 12:51:24,290 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:51:27,536 - INFO -   score=0.7602
2025-12-19 12:51:27,537 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:51:30,880 - INFO -   score=0.5000
2025-12-19 12:51:30,880 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:51:34,243 - INFO -   score=0.5000
2025-12-19 12:51:34,243 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:51:36,401 - INFO -   score=0.9849
2025-12-19 12:51:36,401 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:51:38,539 - INFO -   score=0.6924
2025-12-19 12:51:38,540 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:51:40,665 - INFO -   score=0.0736
2025-12-19 12:51:40,665 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:51:42,792 - INFO -   score=0.0655
2025-12-19 12:51:42,792 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:51:44,941 - INFO -   score=0.9786
2025-12-19 12:51:44,941 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:51:47,070 - INFO -   score=0.8857
2025-12-19 12:51:47,070 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:51:49,229 - INFO -   score=0.0795
2025-12-19 12:51:49,229 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:51:51,439 - INFO -   score=0.0683
2025-12-19 12:51:51,439 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:51:53,488 - INFO -   score=0.5000
2025-12-19 12:51:53,489 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:51:55,574 - INFO -   score=0.8259
2025-12-19 12:51:55,575 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:51:57,706 - INFO -   score=0.5000
2025-12-19 12:51:57,707 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:51:59,840 - INFO -   score=0.5000
2025-12-19 12:51:59,840 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:52:02,045 - INFO -   score=0.9823
2025-12-19 12:52:02,046 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:52:04,253 - INFO -   score=0.7657
2025-12-19 12:52:04,254 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:52:06,455 - INFO -   score=0.0672
2025-12-19 12:52:06,455 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:52:08,640 - INFO -   score=0.0695
2025-12-19 12:52:08,640 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:52:10,843 - INFO -   score=0.9855
2025-12-19 12:52:10,843 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:52:13,045 - INFO -   score=0.9599
2025-12-19 12:52:13,046 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:52:15,274 - INFO -   score=0.0780
2025-12-19 12:52:15,274 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:52:17,518 - INFO -   score=0.0737
2025-12-19 12:52:17,518 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:52:19,639 - INFO -   score=0.5000
2025-12-19 12:52:19,639 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:52:21,790 - INFO -   score=0.8348
2025-12-19 12:52:21,790 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:52:23,990 - INFO -   score=0.5000
2025-12-19 12:52:23,990 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:52:26,180 - INFO -   score=0.5000
2025-12-19 12:52:26,180 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:52:28,355 - INFO -   score=0.9865
2025-12-19 12:52:28,355 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:52:30,546 - INFO -   score=0.7546
2025-12-19 12:52:30,547 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:52:32,716 - INFO -   score=0.0665
2025-12-19 12:52:32,716 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:52:34,908 - INFO -   score=0.0671
2025-12-19 12:52:34,908 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:52:37,073 - INFO -   score=0.9789
2025-12-19 12:52:37,073 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:52:39,245 - INFO -   score=0.9095
2025-12-19 12:52:39,245 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:52:41,454 - INFO -   score=0.0782
2025-12-19 12:52:41,454 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:52:43,677 - INFO -   score=0.0741
2025-12-19 12:52:43,677 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:52:45,790 - INFO -   score=0.5000
2025-12-19 12:52:45,791 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:52:47,927 - INFO -   score=0.5002
2025-12-19 12:52:47,927 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:52:50,086 - INFO -   score=0.5000
2025-12-19 12:52:50,086 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:52:52,252 - INFO -   score=0.5000
2025-12-19 12:52:52,252 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:52:54,671 - INFO -   score=0.9872
2025-12-19 12:52:54,671 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:52:57,086 - INFO -   score=0.8079
2025-12-19 12:52:57,086 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:52:59,479 - INFO -   score=0.0638
2025-12-19 12:52:59,479 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:53:01,857 - INFO -   score=0.0622
2025-12-19 12:53:01,858 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:53:04,254 - INFO -   score=0.9901
2025-12-19 12:53:04,255 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:53:06,672 - INFO -   score=0.9649
2025-12-19 12:53:06,672 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:53:09,101 - INFO -   score=0.0785
2025-12-19 12:53:09,101 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:53:11,582 - INFO -   score=0.0694
2025-12-19 12:53:11,582 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:53:13,920 - INFO -   score=0.5000
2025-12-19 12:53:13,920 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:53:16,281 - INFO -   score=0.8205
2025-12-19 12:53:16,281 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:53:18,693 - INFO -   score=0.5000
2025-12-19 12:53:18,693 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:53:21,111 - INFO -   score=0.5000
2025-12-19 12:53:21,111 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:53:23,288 - INFO -   score=0.9812
2025-12-19 12:53:23,288 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:53:25,450 - INFO -   score=0.7008
2025-12-19 12:53:25,450 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:53:27,594 - INFO -   score=0.0652
2025-12-19 12:53:27,594 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:53:29,747 - INFO -   score=0.0675
2025-12-19 12:53:29,747 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:53:31,904 - INFO -   score=0.9781
2025-12-19 12:53:31,905 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:53:34,077 - INFO -   score=0.9243
2025-12-19 12:53:34,077 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:53:36,262 - INFO -   score=0.0780
2025-12-19 12:53:36,262 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:53:38,463 - INFO -   score=0.0693
2025-12-19 12:53:38,463 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:53:40,522 - INFO -   score=0.5000
2025-12-19 12:53:40,522 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:53:42,607 - INFO -   score=0.7392
2025-12-19 12:53:42,607 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:53:44,761 - INFO -   score=0.5000
2025-12-19 12:53:44,761 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:53:46,897 - INFO -   score=0.5000
2025-12-19 12:53:46,897 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:53:49,189 - INFO -   score=0.9843
2025-12-19 12:53:49,189 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:53:51,548 - INFO -   score=0.7599
2025-12-19 12:53:51,548 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:53:53,828 - INFO -   score=0.0699
2025-12-19 12:53:53,828 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:53:56,117 - INFO -   score=0.0675
2025-12-19 12:53:56,117 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:53:58,421 - INFO -   score=0.9777
2025-12-19 12:53:58,422 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:54:00,843 - INFO -   score=0.9682
2025-12-19 12:54:00,843 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:54:03,207 - INFO -   score=0.0778
2025-12-19 12:54:03,207 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:54:05,590 - INFO -   score=0.0772
2025-12-19 12:54:05,590 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:54:07,821 - INFO -   score=0.5000
2025-12-19 12:54:07,821 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:54:10,067 - INFO -   score=0.7581
2025-12-19 12:54:10,067 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:54:12,342 - INFO -   score=0.5000
2025-12-19 12:54:12,342 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 32, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:54:14,628 - INFO -   score=0.5000
2025-12-19 12:54:14,628 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:54:16,897 - INFO -   score=0.9828
2025-12-19 12:54:16,897 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:54:19,174 - INFO -   score=0.7693
2025-12-19 12:54:19,174 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:54:21,428 - INFO -   score=0.0655
2025-12-19 12:54:21,428 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:54:23,640 - INFO -   score=0.0651
2025-12-19 12:54:23,640 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:54:25,901 - INFO -   score=0.9814
2025-12-19 12:54:25,901 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:54:28,180 - INFO -   score=0.9171
2025-12-19 12:54:28,180 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:54:30,483 - INFO -   score=0.0778
2025-12-19 12:54:30,483 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:54:32,796 - INFO -   score=0.0728
2025-12-19 12:54:32,796 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:54:35,020 - INFO -   score=0.5000
2025-12-19 12:54:35,020 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:54:37,223 - INFO -   score=0.7781
2025-12-19 12:54:37,223 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:54:39,428 - INFO -   score=0.5000
2025-12-19 12:54:39,428 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 64, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:54:41,678 - INFO -   score=0.5000
2025-12-19 12:54:41,678 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:54:44,204 - INFO -   score=0.9866
2025-12-19 12:54:44,204 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:54:46,722 - INFO -   score=0.7963
2025-12-19 12:54:46,722 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:54:49,222 - INFO -   score=0.0615
2025-12-19 12:54:49,222 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:54:51,754 - INFO -   score=0.0640
2025-12-19 12:54:51,754 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:54:54,305 - INFO -   score=0.9798
2025-12-19 12:54:54,306 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:54:56,847 - INFO -   score=0.9552
2025-12-19 12:54:56,847 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:54:59,366 - INFO -   score=0.0776
2025-12-19 12:54:59,366 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:55:01,915 - INFO -   score=0.0743
2025-12-19 12:55:01,915 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:55:04,387 - INFO -   score=0.5000
2025-12-19 12:55:04,388 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:55:06,794 - INFO -   score=0.7441
2025-12-19 12:55:06,794 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 12:55:09,260 - INFO -   score=0.5000
2025-12-19 12:55:09,260 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.4, 'f1': 64, 'f2': 128, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam'}
2025-12-19 12:55:11,711 - INFO -   score=0.5000
2025-12-19 12:55:11,712 - INFO - 
--- Tuning LGSTM ---
2025-12-19 12:55:11,712 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:55:13,341 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 5.11 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 824.00 MiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 44.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:13,341 - INFO -   score=0.0000
2025-12-19 12:55:13,341 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:55:14,941 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 5.12 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 824.00 MiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 44.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:14,941 - INFO -   score=0.0000
2025-12-19 12:55:14,941 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:55:17,214 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.87 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:17,214 - INFO -   score=0.0000
2025-12-19 12:55:17,214 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:55:19,613 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.87 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:19,613 - INFO -   score=0.0000
2025-12-19 12:55:19,614 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:55:21,227 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.87 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:21,227 - INFO -   score=0.0000
2025-12-19 12:55:21,227 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:55:22,859 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.87 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 296.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:22,859 - INFO -   score=0.0000
2025-12-19 12:55:22,859 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:55:25,126 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.87 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:25,127 - INFO -   score=0.0000
2025-12-19 12:55:25,127 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:55:27,521 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.87 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:27,521 - INFO -   score=0.0000
2025-12-19 12:55:27,521 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:55:29,140 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.87 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:29,140 - INFO -   score=0.0000
2025-12-19 12:55:29,140 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:55:30,777 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.86 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 296.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:30,777 - INFO -   score=0.0000
2025-12-19 12:55:30,777 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:55:33,046 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.87 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:33,046 - INFO -   score=0.0000
2025-12-19 12:55:33,046 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:55:35,447 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.87 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:35,447 - INFO -   score=0.0000
2025-12-19 12:55:35,447 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:55:37,037 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.87 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:37,037 - INFO -   score=0.0000
2025-12-19 12:55:37,037 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:55:38,639 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.87 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 296.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:38,639 - INFO -   score=0.0000
2025-12-19 12:55:38,640 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:55:40,914 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.85 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:40,914 - INFO -   score=0.0000
2025-12-19 12:55:40,914 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:55:43,307 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.85 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:43,307 - INFO -   score=0.0000
2025-12-19 12:55:43,307 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:55:44,901 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.85 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:44,901 - INFO -   score=0.0000
2025-12-19 12:55:44,901 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:55:46,508 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.84 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 296.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:46,509 - INFO -   score=0.0000
2025-12-19 12:55:46,509 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:55:48,781 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.83 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:48,781 - INFO -   score=0.0000
2025-12-19 12:55:48,781 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:55:51,172 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.84 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:51,173 - INFO -   score=0.0000
2025-12-19 12:55:51,173 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:55:52,770 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.84 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:52,770 - INFO -   score=0.0000
2025-12-19 12:55:52,770 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:55:54,363 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.84 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 296.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:54,363 - INFO -   score=0.0000
2025-12-19 12:55:54,363 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:55:56,655 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.85 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:56,656 - INFO -   score=0.0000
2025-12-19 12:55:56,656 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:55:59,074 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.86 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:55:59,074 - INFO -   score=0.0000
2025-12-19 12:55:59,074 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:56:00,737 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.86 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.50 MiB is allocated by PyTorch, and 298.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:00,738 - INFO -   score=0.0000
2025-12-19 12:56:00,738 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:56:02,379 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.86 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.81 MiB is allocated by PyTorch, and 296.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:02,380 - INFO -   score=0.0000
2025-12-19 12:56:02,380 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:56:04,658 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.87 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.54 MiB is allocated by PyTorch, and 37.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:04,659 - INFO -   score=0.0000
2025-12-19 12:56:04,659 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:56:07,066 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.87 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.98 MiB is allocated by PyTorch, and 37.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:07,066 - INFO -   score=0.0000
2025-12-19 12:56:07,067 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:56:08,707 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.87 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.50 MiB is allocated by PyTorch, and 298.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:08,708 - INFO -   score=0.0000
2025-12-19 12:56:08,708 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:56:10,392 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.87 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.81 MiB is allocated by PyTorch, and 296.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:10,393 - INFO -   score=0.0000
2025-12-19 12:56:10,393 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:56:12,722 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.86 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.54 MiB is allocated by PyTorch, and 37.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:12,723 - INFO -   score=0.0000
2025-12-19 12:56:12,723 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:56:15,163 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.86 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.98 MiB is allocated by PyTorch, and 37.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:15,164 - INFO -   score=0.0000
2025-12-19 12:56:15,164 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:56:16,802 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:16,802 - INFO -   score=0.0000
2025-12-19 12:56:16,802 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:56:18,458 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.73 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 296.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:18,458 - INFO -   score=0.0000
2025-12-19 12:56:18,458 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:56:20,759 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.66 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:20,759 - INFO -   score=0.0000
2025-12-19 12:56:20,759 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:56:23,214 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.79 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:23,214 - INFO -   score=0.0000
2025-12-19 12:56:23,214 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:56:24,800 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.80 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:24,800 - INFO -   score=0.0000
2025-12-19 12:56:24,800 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:56:26,380 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.80 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 296.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:26,380 - INFO -   score=0.0000
2025-12-19 12:56:26,380 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:56:28,633 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.84 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:28,634 - INFO -   score=0.0000
2025-12-19 12:56:28,634 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:56:31,039 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.84 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:31,039 - INFO -   score=0.0000
2025-12-19 12:56:31,040 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:56:32,757 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.50 MiB is allocated by PyTorch, and 298.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:32,758 - INFO -   score=0.0000
2025-12-19 12:56:32,758 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:56:34,417 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.78 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.81 MiB is allocated by PyTorch, and 296.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:34,418 - INFO -   score=0.0000
2025-12-19 12:56:34,418 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:56:36,714 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.68 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.54 MiB is allocated by PyTorch, and 37.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:36,715 - INFO -   score=0.0000
2025-12-19 12:56:36,715 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:56:39,130 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.70 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.98 MiB is allocated by PyTorch, and 37.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:39,131 - INFO -   score=0.0000
2025-12-19 12:56:39,131 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:56:40,841 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.68 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.50 MiB is allocated by PyTorch, and 298.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:40,842 - INFO -   score=0.0000
2025-12-19 12:56:40,842 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:56:42,527 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.72 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.81 MiB is allocated by PyTorch, and 296.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:42,528 - INFO -   score=0.0000
2025-12-19 12:56:42,528 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:56:44,811 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.54 MiB is allocated by PyTorch, and 37.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:44,812 - INFO -   score=0.0000
2025-12-19 12:56:44,812 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:56:47,248 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.98 MiB is allocated by PyTorch, and 37.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:47,249 - INFO -   score=0.0000
2025-12-19 12:56:47,249 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:56:48,848 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:48,848 - INFO -   score=0.0000
2025-12-19 12:56:48,848 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:56:50,446 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 296.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:50,446 - INFO -   score=0.0000
2025-12-19 12:56:50,446 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:56:52,714 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:52,714 - INFO -   score=0.0000
2025-12-19 12:56:52,714 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:56:55,121 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:55,121 - INFO -   score=0.0000
2025-12-19 12:56:55,121 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:56:56,713 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:56,713 - INFO -   score=0.0000
2025-12-19 12:56:56,713 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:56:58,302 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 296.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:56:58,302 - INFO -   score=0.0000
2025-12-19 12:56:58,302 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:57:00,562 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.73 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:00,562 - INFO -   score=0.0000
2025-12-19 12:57:00,562 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:57:02,966 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.72 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:02,966 - INFO -   score=0.0000
2025-12-19 12:57:02,966 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:57:04,578 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.71 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:04,578 - INFO -   score=0.0000
2025-12-19 12:57:04,578 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:57:06,201 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.72 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 296.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:06,201 - INFO -   score=0.0000
2025-12-19 12:57:06,201 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:57:08,471 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:08,471 - INFO -   score=0.0000
2025-12-19 12:57:08,471 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:57:10,868 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.73 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:10,869 - INFO -   score=0.0000
2025-12-19 12:57:10,869 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:57:12,455 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.73 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:12,455 - INFO -   score=0.0000
2025-12-19 12:57:12,455 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:57:14,048 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 296.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:14,048 - INFO -   score=0.0000
2025-12-19 12:57:14,048 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:57:16,316 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.72 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:16,316 - INFO -   score=0.0000
2025-12-19 12:57:16,316 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:57:18,723 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.78 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:18,723 - INFO -   score=0.0000
2025-12-19 12:57:18,723 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:57:20,323 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.78 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:20,323 - INFO -   score=0.0000
2025-12-19 12:57:20,323 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:57:21,928 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 296.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:21,928 - INFO -   score=0.0000
2025-12-19 12:57:21,928 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:57:24,197 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.78 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:24,198 - INFO -   score=0.0000
2025-12-19 12:57:24,198 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:57:26,588 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.78 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:26,588 - INFO -   score=0.0000
2025-12-19 12:57:26,588 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:57:28,177 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.82 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:28,177 - INFO -   score=0.0000
2025-12-19 12:57:28,177 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:57:29,770 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.82 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 296.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:29,770 - INFO -   score=0.0000
2025-12-19 12:57:29,770 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:57:32,032 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.82 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:32,032 - INFO -   score=0.0000
2025-12-19 12:57:32,032 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:57:34,432 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.75 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:34,432 - INFO -   score=0.0000
2025-12-19 12:57:34,432 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:57:36,109 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.50 MiB is allocated by PyTorch, and 298.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:36,109 - INFO -   score=0.0000
2025-12-19 12:57:36,109 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:57:37,767 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.81 MiB is allocated by PyTorch, and 296.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:37,768 - INFO -   score=0.0000
2025-12-19 12:57:37,768 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:57:40,067 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.54 MiB is allocated by PyTorch, and 37.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:40,068 - INFO -   score=0.0000
2025-12-19 12:57:40,068 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:57:42,504 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.98 MiB is allocated by PyTorch, and 37.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:42,504 - INFO -   score=0.0000
2025-12-19 12:57:42,504 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:57:44,212 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.75 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.50 MiB is allocated by PyTorch, and 298.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:44,213 - INFO -   score=0.0000
2025-12-19 12:57:44,213 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:57:45,879 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.81 MiB is allocated by PyTorch, and 296.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:45,879 - INFO -   score=0.0000
2025-12-19 12:57:45,879 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:57:48,174 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.78 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.54 MiB is allocated by PyTorch, and 37.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:48,175 - INFO -   score=0.0000
2025-12-19 12:57:48,175 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:57:50,594 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.78 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.98 MiB is allocated by PyTorch, and 37.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:50,595 - INFO -   score=0.0000
2025-12-19 12:57:50,595 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:57:52,203 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:52,203 - INFO -   score=0.0000
2025-12-19 12:57:52,203 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:57:53,844 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 296.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:53,845 - INFO -   score=0.0000
2025-12-19 12:57:53,845 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:57:56,110 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:56,110 - INFO -   score=0.0000
2025-12-19 12:57:56,110 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:57:58,514 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.73 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:57:58,514 - INFO -   score=0.0000
2025-12-19 12:57:58,514 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:58:00,126 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.73 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:00,126 - INFO -   score=0.0000
2025-12-19 12:58:00,126 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:58:01,745 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.73 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 296.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:01,745 - INFO -   score=0.0000
2025-12-19 12:58:01,745 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:58:04,063 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:04,063 - INFO -   score=0.0000
2025-12-19 12:58:04,063 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:58:06,462 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:06,462 - INFO -   score=0.0000
2025-12-19 12:58:06,462 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:58:08,139 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.50 MiB is allocated by PyTorch, and 298.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:08,140 - INFO -   score=0.0000
2025-12-19 12:58:08,140 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:58:09,840 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.81 MiB is allocated by PyTorch, and 296.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:09,840 - INFO -   score=0.0000
2025-12-19 12:58:09,841 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:58:12,126 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.79 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.54 MiB is allocated by PyTorch, and 37.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:12,126 - INFO -   score=0.0000
2025-12-19 12:58:12,127 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:58:14,547 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.79 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.98 MiB is allocated by PyTorch, and 37.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:14,547 - INFO -   score=0.0000
2025-12-19 12:58:14,548 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:58:16,234 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.78 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.50 MiB is allocated by PyTorch, and 298.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:16,234 - INFO -   score=0.0000
2025-12-19 12:58:16,234 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:58:17,931 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.78 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.81 MiB is allocated by PyTorch, and 296.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:17,932 - INFO -   score=0.0000
2025-12-19 12:58:17,932 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:58:20,226 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.54 MiB is allocated by PyTorch, and 37.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:20,227 - INFO -   score=0.0000
2025-12-19 12:58:20,227 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:58:22,654 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.75 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.98 MiB is allocated by PyTorch, and 37.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:22,655 - INFO -   score=0.0000
2025-12-19 12:58:22,655 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:58:23,611 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.75 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:23,611 - INFO -   score=0.0000
2025-12-19 12:58:23,611 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:58:24,622 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.78 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 298.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:24,622 - INFO -   score=0.0000
2025-12-19 12:58:24,622 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:58:26,593 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.78 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:26,593 - INFO -   score=0.0000
2025-12-19 12:58:26,593 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:58:28,692 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.79 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:28,692 - INFO -   score=0.0000
2025-12-19 12:58:28,693 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:58:29,675 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:29,675 - INFO -   score=0.0000
2025-12-19 12:58:29,675 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:58:30,758 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 298.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:30,758 - INFO -   score=0.0000
2025-12-19 12:58:30,758 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:58:32,796 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:32,796 - INFO -   score=0.0000
2025-12-19 12:58:32,796 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:58:34,920 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.79 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:34,920 - INFO -   score=0.0000
2025-12-19 12:58:34,920 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:58:35,850 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.79 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:35,851 - INFO -   score=0.0000
2025-12-19 12:58:35,851 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:58:36,848 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.79 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 298.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:36,848 - INFO -   score=0.0000
2025-12-19 12:58:36,848 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:58:38,843 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.79 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:38,843 - INFO -   score=0.0000
2025-12-19 12:58:38,843 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:58:40,967 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.79 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:40,967 - INFO -   score=0.0000
2025-12-19 12:58:40,967 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:58:41,901 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.79 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:41,901 - INFO -   score=0.0000
2025-12-19 12:58:41,901 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:58:42,907 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.79 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 298.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:42,907 - INFO -   score=0.0000
2025-12-19 12:58:42,907 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:58:44,912 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.80 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:44,913 - INFO -   score=0.0000
2025-12-19 12:58:44,913 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:58:47,068 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.75 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:47,068 - INFO -   score=0.0000
2025-12-19 12:58:47,068 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:58:48,011 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.73 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:48,011 - INFO -   score=0.0000
2025-12-19 12:58:48,011 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:58:49,008 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.73 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 298.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:49,008 - INFO -   score=0.0000
2025-12-19 12:58:49,008 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:58:50,992 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:50,992 - INFO -   score=0.0000
2025-12-19 12:58:50,992 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:58:53,114 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:53,114 - INFO -   score=0.0000
2025-12-19 12:58:53,114 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:58:54,074 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.73 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:54,074 - INFO -   score=0.0000
2025-12-19 12:58:54,074 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:58:55,078 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 298.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:55,078 - INFO -   score=0.0000
2025-12-19 12:58:55,078 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:58:57,081 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:57,081 - INFO -   score=0.0000
2025-12-19 12:58:57,082 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:58:59,215 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:58:59,215 - INFO -   score=0.0000
2025-12-19 12:58:59,215 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:59:00,191 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.50 MiB is allocated by PyTorch, and 296.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:00,192 - INFO -   score=0.0000
2025-12-19 12:59:00,192 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:59:01,203 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.81 MiB is allocated by PyTorch, and 296.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:01,203 - INFO -   score=0.0000
2025-12-19 12:59:01,204 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:59:03,213 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.78 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.54 MiB is allocated by PyTorch, and 37.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:03,214 - INFO -   score=0.0000
2025-12-19 12:59:03,214 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:59:05,332 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.78 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.98 MiB is allocated by PyTorch, and 39.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:05,333 - INFO -   score=0.0000
2025-12-19 12:59:05,333 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:59:06,296 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.78 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.50 MiB is allocated by PyTorch, and 296.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:06,297 - INFO -   score=0.0000
2025-12-19 12:59:06,297 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:59:07,309 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.78 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.81 MiB is allocated by PyTorch, and 296.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:07,310 - INFO -   score=0.0000
2025-12-19 12:59:07,310 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:59:09,291 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.78 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.54 MiB is allocated by PyTorch, and 37.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:09,292 - INFO -   score=0.0000
2025-12-19 12:59:09,292 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:59:11,417 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.98 MiB is allocated by PyTorch, and 39.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:11,418 - INFO -   score=0.0000
2025-12-19 12:59:11,418 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:59:12,355 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:12,355 - INFO -   score=0.0000
2025-12-19 12:59:12,355 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:59:13,352 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 298.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:13,352 - INFO -   score=0.0000
2025-12-19 12:59:13,352 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:59:15,339 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:15,339 - INFO -   score=0.0000
2025-12-19 12:59:15,339 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:59:17,490 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.72 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:17,490 - INFO -   score=0.0000
2025-12-19 12:59:17,490 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:59:18,446 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.69 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:18,446 - INFO -   score=0.0000
2025-12-19 12:59:18,446 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:59:19,466 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.69 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 298.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:19,467 - INFO -   score=0.0000
2025-12-19 12:59:19,467 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:59:21,486 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.71 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:21,486 - INFO -   score=0.0000
2025-12-19 12:59:21,486 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:59:23,610 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.71 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:23,610 - INFO -   score=0.0000
2025-12-19 12:59:23,610 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:59:24,603 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.72 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.50 MiB is allocated by PyTorch, and 296.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:24,604 - INFO -   score=0.0000
2025-12-19 12:59:24,604 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:59:25,621 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.75 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.81 MiB is allocated by PyTorch, and 296.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:25,622 - INFO -   score=0.0000
2025-12-19 12:59:25,622 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:59:27,655 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.70 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.54 MiB is allocated by PyTorch, and 37.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:27,656 - INFO -   score=0.0000
2025-12-19 12:59:27,656 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:59:29,797 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.98 MiB is allocated by PyTorch, and 39.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:29,798 - INFO -   score=0.0000
2025-12-19 12:59:29,798 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:59:30,781 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.73 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.50 MiB is allocated by PyTorch, and 296.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:30,782 - INFO -   score=0.0000
2025-12-19 12:59:30,782 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:59:31,801 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.81 MiB is allocated by PyTorch, and 296.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:31,802 - INFO -   score=0.0000
2025-12-19 12:59:31,802 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:59:33,837 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.71 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.54 MiB is allocated by PyTorch, and 37.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:33,838 - INFO -   score=0.0000
2025-12-19 12:59:33,838 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:59:35,975 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.71 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.98 MiB is allocated by PyTorch, and 39.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:35,976 - INFO -   score=0.0000
2025-12-19 12:59:35,976 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:59:36,927 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.71 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:36,927 - INFO -   score=0.0000
2025-12-19 12:59:36,927 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:59:37,938 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.72 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 298.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:37,938 - INFO -   score=0.0000
2025-12-19 12:59:37,938 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:59:39,926 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.75 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:39,927 - INFO -   score=0.0000
2025-12-19 12:59:39,927 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:59:42,060 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:42,060 - INFO -   score=0.0000
2025-12-19 12:59:42,060 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:59:42,996 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.51 MiB is allocated by PyTorch, and 296.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:42,996 - INFO -   score=0.0000
2025-12-19 12:59:42,996 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:59:44,007 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.82 MiB is allocated by PyTorch, and 298.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:44,007 - INFO -   score=0.0000
2025-12-19 12:59:44,007 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:59:45,987 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.75 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.42 MiB is allocated by PyTorch, and 37.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:45,988 - INFO -   score=0.0000
2025-12-19 12:59:45,988 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:59:48,114 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.87 MiB is allocated by PyTorch, and 39.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:48,114 - INFO -   score=0.0000
2025-12-19 12:59:48,114 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:59:49,066 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.38 MiB is allocated by PyTorch, and 296.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:49,066 - INFO -   score=0.0000
2025-12-19 12:59:49,066 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:59:50,082 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.70 MiB is allocated by PyTorch, and 296.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:50,082 - INFO -   score=0.0000
2025-12-19 12:59:50,082 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:59:52,072 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.73 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.42 MiB is allocated by PyTorch, and 37.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:52,072 - INFO -   score=0.0000
2025-12-19 12:59:52,072 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 12:59:54,189 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.73 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.87 MiB is allocated by PyTorch, and 39.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:54,189 - INFO -   score=0.0000
2025-12-19 12:59:54,189 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 12:59:55,145 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.73 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.38 MiB is allocated by PyTorch, and 296.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:55,145 - INFO -   score=0.0000
2025-12-19 12:59:55,145 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 12:59:56,174 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.73 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.70 MiB is allocated by PyTorch, and 296.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:56,174 - INFO -   score=0.0000
2025-12-19 12:59:56,174 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 12:59:58,186 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.72 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.42 MiB is allocated by PyTorch, and 37.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 12:59:58,186 - INFO -   score=0.0000
2025-12-19 12:59:58,186 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'sigmoid', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 13:00:00,319 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.73 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.87 MiB is allocated by PyTorch, and 39.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:00,319 - INFO -   score=0.0000
2025-12-19 13:00:00,319 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 13:00:01,293 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.38 MiB is allocated by PyTorch, and 296.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:01,293 - INFO -   score=0.0000
2025-12-19 13:00:01,293 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 13:00:02,325 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.79 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.70 MiB is allocated by PyTorch, and 296.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:02,325 - INFO -   score=0.0000
2025-12-19 13:00:02,325 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 13:00:04,376 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.42 MiB is allocated by PyTorch, and 37.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:04,376 - INFO -   score=0.0000
2025-12-19 13:00:04,376 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 13:00:06,499 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.75 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.87 MiB is allocated by PyTorch, and 39.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:06,500 - INFO -   score=0.0000
2025-12-19 13:00:06,500 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 13:00:07,523 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.75 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.38 MiB is allocated by PyTorch, and 296.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:07,524 - INFO -   score=0.0000
2025-12-19 13:00:07,524 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 13:00:08,568 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.70 MiB is allocated by PyTorch, and 296.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:08,568 - INFO -   score=0.0000
2025-12-19 13:00:08,568 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 13:00:10,561 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.42 MiB is allocated by PyTorch, and 37.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:10,561 - INFO -   score=0.0000
2025-12-19 13:00:10,561 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 13:00:12,696 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.87 MiB is allocated by PyTorch, and 39.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:12,696 - INFO -   score=0.0000
2025-12-19 13:00:12,696 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 13:00:13,659 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.37 MiB is allocated by PyTorch, and 296.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:13,660 - INFO -   score=0.0000
2025-12-19 13:00:13,660 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 13:00:14,687 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.76 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.69 MiB is allocated by PyTorch, and 296.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:14,687 - INFO -   score=0.0000
2025-12-19 13:00:14,687 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 13:00:16,681 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.80 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.41 MiB is allocated by PyTorch, and 37.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:16,682 - INFO -   score=0.0000
2025-12-19 13:00:16,682 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 13:00:18,822 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.80 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.85 MiB is allocated by PyTorch, and 37.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:18,823 - INFO -   score=0.0000
2025-12-19 13:00:18,823 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 13:00:19,804 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.80 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.37 MiB is allocated by PyTorch, and 296.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:19,805 - INFO -   score=0.0000
2025-12-19 13:00:19,805 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 13:00:20,839 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.80 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.69 MiB is allocated by PyTorch, and 296.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:20,839 - INFO -   score=0.0000
2025-12-19 13:00:20,839 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 13:00:22,840 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.80 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.41 MiB is allocated by PyTorch, and 37.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:22,841 - INFO -   score=0.0000
2025-12-19 13:00:22,841 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'tanh', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 13:00:24,994 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.78 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.85 MiB is allocated by PyTorch, and 37.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:24,995 - INFO -   score=0.0000
2025-12-19 13:00:24,995 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 13:00:25,946 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.78 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.38 MiB is allocated by PyTorch, and 296.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:25,946 - INFO -   score=0.0000
2025-12-19 13:00:25,946 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 13:00:26,942 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.79 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.70 MiB is allocated by PyTorch, and 296.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:26,942 - INFO -   score=0.0000
2025-12-19 13:00:26,942 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 13:00:28,945 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.80 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.42 MiB is allocated by PyTorch, and 37.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:28,946 - INFO -   score=0.0000
2025-12-19 13:00:28,946 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 13:00:31,060 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.83 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.87 MiB is allocated by PyTorch, and 39.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:31,060 - INFO -   score=0.0000
2025-12-19 13:00:31,060 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 13:00:32,013 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.83 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.38 MiB is allocated by PyTorch, and 296.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:32,014 - INFO -   score=0.0000
2025-12-19 13:00:32,014 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 13:00:33,020 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.84 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.70 MiB is allocated by PyTorch, and 296.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:33,020 - INFO -   score=0.0000
2025-12-19 13:00:33,020 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 13:00:35,005 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.84 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.42 MiB is allocated by PyTorch, and 37.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:35,005 - INFO -   score=0.0000
2025-12-19 13:00:35,005 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'mse', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 13:00:37,163 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.79 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.87 MiB is allocated by PyTorch, and 39.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:37,163 - INFO -   score=0.0000
2025-12-19 13:00:37,163 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 13:00:38,181 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.72 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.37 MiB is allocated by PyTorch, and 296.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:38,183 - INFO -   score=0.0000
2025-12-19 13:00:38,183 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 13:00:39,207 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.72 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.69 MiB is allocated by PyTorch, and 296.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:39,208 - INFO -   score=0.0000
2025-12-19 13:00:39,208 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 13:00:41,209 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.74 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.41 MiB is allocated by PyTorch, and 37.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:41,210 - INFO -   score=0.0000
2025-12-19 13:00:41,210 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 13:00:43,340 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.80 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.85 MiB is allocated by PyTorch, and 37.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:43,341 - INFO -   score=0.0000
2025-12-19 13:00:43,341 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 13:00:44,318 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.79 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.37 MiB is allocated by PyTorch, and 296.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:44,318 - INFO -   score=0.0000
2025-12-19 13:00:44,318 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 13:00:45,337 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.79 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 597.69 MiB is allocated by PyTorch, and 296.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:45,338 - INFO -   score=0.0000
2025-12-19 13:00:45,338 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 13:00:47,346 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.41 MiB is allocated by PyTorch, and 37.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:47,347 - INFO -   score=0.0000
2025-12-19 13:00:47,347 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.4, 'final_activation': 'relu', 'loss': 'hinge', 'lr': 0.0001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 13:00:49,478 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 4.77 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 854.85 MiB is allocated by PyTorch, and 37.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:00:49,479 - INFO -   score=0.0000
2025-12-19 13:00:49,480 - INFO - 
✓ Overall Best Model: CNN (score=0.9901)
2025-12-19 13:00:49,480 - INFO -   Best Config: {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'tanh', 'loss': 'mse', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 13:00:49,480 - INFO - 
=== FINAL EXPERIMENTS ===

2025-12-19 13:00:49,480 - INFO - Training CNN for 10 epochs...
2025-12-19 13:00:58,770 - INFO -   Test AUC: 0.9858, F1: 0.0877
2025-12-19 13:00:58,770 - INFO - Training CNN for 20 epochs...
2025-12-19 13:01:16,171 - INFO -   Test AUC: 0.9692, F1: 0.0862
2025-12-19 13:01:16,171 - INFO - Preparing data for PhysioNet Official Scoring...
2025-12-19 13:01:16,212 - INFO - Scoring on 4035 test patients...
2025-12-19 13:01:16,276 - INFO - 
========================================
2025-12-19 13:01:16,276 - INFO - OFFICIAL PHYSIONET UTILITY SCORE
2025-12-19 13:01:16,276 - INFO - ========================================
2025-12-19 13:01:16,276 - INFO - Model: CNN
2025-12-19 13:01:16,276 - INFO - Normalized Utility Score: -0.1066
2025-12-19 13:01:16,276 - INFO - Raw Utility Score:        -342.80
2025-12-19 13:01:16,276 - INFO - ----------------------------------------
2025-12-19 13:01:16,276 - INFO - ========================================
2025-12-19 13:01:16,276 - INFO - 
Generating Plots...
2025-12-19 13:01:16,321 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-12-19 13:01:16,323 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-12-19 13:07:46,409 - INFO - Using device: cuda
2025-12-19 13:07:46,410 - INFO - Loading preprocessed data from preprocessed_data.pkl...
2025-12-19 13:07:46,856 - INFO - ✓ Data loaded from cache.
2025-12-19 13:07:46,856 - INFO - Train: torch.Size([32268, 256, 41]), Val: torch.Size([4033, 256, 41]), Test: torch.Size([4035, 256, 41])
2025-12-19 13:07:46,857 - INFO - === FULL GRID SEARCH ON ALL MODELS (PYTORCH) ===

2025-12-19 13:07:46,857 - INFO - --- Tuning RNN (15 epochs) ---
2025-12-19 13:07:46,857 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 13:08:05,065 - INFO -   score=0.9915
2025-12-19 13:08:05,066 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 13:08:23,138 - INFO -   score=0.9909
2025-12-19 13:08:23,139 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 256}
2025-12-19 13:08:25,011 - INFO -   fit failed: CUDA out of memory. Tried to allocate 6.09 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.57 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 1.33 GiB is allocated by PyTorch, and 713.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:08:25,011 - INFO -   score=0.0000
2025-12-19 13:08:25,011 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'units': 64}
2025-12-19 13:08:43,013 - INFO -   score=0.9906
2025-12-19 13:08:43,013 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'units': 128}
2025-12-19 13:09:01,284 - INFO -   score=0.9916
2025-12-19 13:09:01,285 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'units': 256}
2025-12-19 13:09:03,111 - INFO -   fit failed: CUDA out of memory. Tried to allocate 6.09 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.57 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 1.33 GiB is allocated by PyTorch, and 713.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:09:03,111 - INFO -   score=0.0000
2025-12-19 13:09:03,111 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 13:09:20,733 - INFO -   score=0.9923
2025-12-19 13:09:20,734 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 13:09:38,376 - INFO -   score=0.9918
2025-12-19 13:09:38,376 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 256}
2025-12-19 13:09:40,190 - INFO -   fit failed: CUDA out of memory. Tried to allocate 6.09 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.58 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 1.33 GiB is allocated by PyTorch, and 713.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:09:40,190 - INFO -   score=0.0000
2025-12-19 13:09:40,190 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'units': 64}
2025-12-19 13:09:57,833 - INFO -   score=0.9908
2025-12-19 13:09:57,833 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'units': 128}
2025-12-19 13:10:15,670 - INFO -   score=0.9907
2025-12-19 13:10:15,670 - INFO - [RNN] trying {'batch_size': 32, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'units': 256}
2025-12-19 13:10:17,488 - INFO -   fit failed: CUDA out of memory. Tried to allocate 6.09 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.57 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 1.33 GiB is allocated by PyTorch, and 713.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:10:17,488 - INFO -   score=0.0000
2025-12-19 13:10:17,488 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 13:10:28,677 - INFO -   score=0.9910
2025-12-19 13:10:28,677 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 13:10:40,029 - INFO -   score=0.9909
2025-12-19 13:10:40,029 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 256}
2025-12-19 13:10:41,748 - INFO -   fit failed: CUDA out of memory. Tried to allocate 6.09 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.60 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 1.33 GiB is allocated by PyTorch, and 713.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:10:41,748 - INFO -   score=0.0000
2025-12-19 13:10:41,748 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'units': 64}
2025-12-19 13:10:53,041 - INFO -   score=0.9901
2025-12-19 13:10:53,042 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'units': 128}
2025-12-19 13:11:04,525 - INFO -   score=0.9915
2025-12-19 13:11:04,525 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'units': 256}
2025-12-19 13:11:06,247 - INFO -   fit failed: CUDA out of memory. Tried to allocate 6.09 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.57 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 1.33 GiB is allocated by PyTorch, and 713.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:11:06,248 - INFO -   score=0.0000
2025-12-19 13:11:06,248 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 64}
2025-12-19 13:11:17,549 - INFO -   score=0.9904
2025-12-19 13:11:17,550 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 128}
2025-12-19 13:11:28,820 - INFO -   score=0.9901
2025-12-19 13:11:28,820 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'units': 256}
2025-12-19 13:11:30,511 - INFO -   fit failed: CUDA out of memory. Tried to allocate 6.09 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.64 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 1.33 GiB is allocated by PyTorch, and 713.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:11:30,511 - INFO -   score=0.0000
2025-12-19 13:11:30,511 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'units': 64}
2025-12-19 13:11:41,598 - INFO -   score=0.9894
2025-12-19 13:11:41,598 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'units': 128}
2025-12-19 13:11:52,911 - INFO -   score=0.9911
2025-12-19 13:11:52,911 - INFO - [RNN] trying {'batch_size': 64, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'units': 256}
2025-12-19 13:11:54,606 - INFO -   fit failed: CUDA out of memory. Tried to allocate 6.09 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.64 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 1.33 GiB is allocated by PyTorch, and 713.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:11:54,606 - INFO -   score=0.0000
2025-12-19 13:11:54,607 - INFO - 
--- Tuning CNN (15 epochs) ---
2025-12-19 13:11:54,607 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 13:12:10,838 - INFO -   score=0.9922
2025-12-19 13:12:10,839 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam'}
2025-12-19 13:12:26,947 - INFO -   score=0.9925
2025-12-19 13:12:26,947 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 13:12:43,338 - INFO -   score=0.9928
2025-12-19 13:12:43,338 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam'}
2025-12-19 13:12:59,702 - INFO -   score=0.9921
2025-12-19 13:12:59,702 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 13:13:15,955 - INFO -   score=0.9925
2025-12-19 13:13:15,955 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam'}
2025-12-19 13:13:32,249 - INFO -   score=0.9921
2025-12-19 13:13:32,249 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 13:13:49,119 - INFO -   score=0.9922
2025-12-19 13:13:49,119 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam'}
2025-12-19 13:14:06,709 - INFO -   score=0.9926
2025-12-19 13:14:06,709 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.5, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 13:14:24,023 - INFO -   score=0.9921
2025-12-19 13:14:24,023 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.5, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam'}
2025-12-19 13:14:41,041 - INFO -   score=0.9916
2025-12-19 13:14:41,041 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.5, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 13:14:57,967 - INFO -   score=0.9922
2025-12-19 13:14:57,967 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.5, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam'}
2025-12-19 13:15:14,904 - INFO -   score=0.9921
2025-12-19 13:15:14,904 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.5, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 13:15:31,744 - INFO -   score=0.9920
2025-12-19 13:15:31,744 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.5, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam'}
2025-12-19 13:15:49,070 - INFO -   score=0.9922
2025-12-19 13:15:49,070 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.5, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 13:16:06,648 - INFO -   score=0.9922
2025-12-19 13:16:06,648 - INFO - [CNN] trying {'batch_size': 32, 'dropout': 0.5, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam'}
2025-12-19 13:16:24,320 - INFO -   score=0.9919
2025-12-19 13:16:24,320 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 13:16:35,748 - INFO -   score=0.9918
2025-12-19 13:16:35,748 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam'}
2025-12-19 13:16:47,094 - INFO -   score=0.9919
2025-12-19 13:16:47,094 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 13:16:58,672 - INFO -   score=0.9920
2025-12-19 13:16:58,672 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam'}
2025-12-19 13:17:10,149 - INFO -   score=0.9923
2025-12-19 13:17:10,149 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 13:17:21,582 - INFO -   score=0.9919
2025-12-19 13:17:21,582 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam'}
2025-12-19 13:17:32,742 - INFO -   score=0.9922
2025-12-19 13:17:32,742 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 13:17:45,351 - INFO -   score=0.9920
2025-12-19 13:17:45,352 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.2, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam'}
2025-12-19 13:17:57,904 - INFO -   score=0.9921
2025-12-19 13:17:57,904 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.5, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 13:18:08,991 - INFO -   score=0.9913
2025-12-19 13:18:08,992 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.5, 'f1': 32, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam'}
2025-12-19 13:18:20,103 - INFO -   score=0.9910
2025-12-19 13:18:20,103 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.5, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 13:18:31,783 - INFO -   score=0.9917
2025-12-19 13:18:31,783 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.5, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam'}
2025-12-19 13:18:43,420 - INFO -   score=0.9909
2025-12-19 13:18:43,420 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.5, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 13:18:54,337 - INFO -   score=0.9920
2025-12-19 13:18:54,337 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.5, 'f1': 64, 'f2': 64, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam'}
2025-12-19 13:19:05,079 - INFO -   score=0.9915
2025-12-19 13:19:05,079 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.5, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 13:19:17,127 - INFO -   score=0.9921
2025-12-19 13:19:17,127 - INFO - [CNN] trying {'batch_size': 64, 'dropout': 0.5, 'f1': 64, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam'}
2025-12-19 13:19:29,150 - INFO -   score=0.9919
2025-12-19 13:19:29,151 - INFO - 
--- Tuning LGSTM (15 epochs) ---
2025-12-19 13:19:29,151 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 13:19:30,750 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.21 GiB memory in use. Of the allocated memory 597.38 MiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:19:30,750 - INFO -   score=0.0000
2025-12-19 13:19:30,750 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 13:19:32,317 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 597.70 MiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:19:32,317 - INFO -   score=0.0000
2025-12-19 13:19:32,317 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 13:19:34,588 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.31 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 854.42 MiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:19:34,588 - INFO -   score=0.0000
2025-12-19 13:19:34,588 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 13:19:36,977 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 854.87 MiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:19:36,977 - INFO -   score=0.0000
2025-12-19 13:19:36,977 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 13:19:38,561 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.21 GiB memory in use. Of the allocated memory 597.38 MiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:19:38,561 - INFO -   score=0.0000
2025-12-19 13:19:38,561 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 13:19:40,151 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 597.70 MiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:19:40,151 - INFO -   score=0.0000
2025-12-19 13:19:40,151 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 13:19:42,404 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.31 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 854.42 MiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:19:42,405 - INFO -   score=0.0000
2025-12-19 13:19:42,405 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 13:19:44,792 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 854.87 MiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:19:44,792 - INFO -   score=0.0000
2025-12-19 13:19:44,792 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 13:19:46,365 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.21 GiB memory in use. Of the allocated memory 597.38 MiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:19:46,365 - INFO -   score=0.0000
2025-12-19 13:19:46,365 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 13:19:47,940 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 597.70 MiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:19:47,940 - INFO -   score=0.0000
2025-12-19 13:19:47,940 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 13:19:50,204 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.31 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 854.42 MiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:19:50,204 - INFO -   score=0.0000
2025-12-19 13:19:50,204 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 13:19:52,584 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 854.87 MiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:19:52,585 - INFO -   score=0.0000
2025-12-19 13:19:52,585 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 13:19:54,186 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.21 GiB memory in use. Of the allocated memory 597.38 MiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:19:54,187 - INFO -   score=0.0000
2025-12-19 13:19:54,187 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 13:19:55,763 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 597.70 MiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:19:55,763 - INFO -   score=0.0000
2025-12-19 13:19:55,763 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 13:19:58,031 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.31 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 854.42 MiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:19:58,031 - INFO -   score=0.0000
2025-12-19 13:19:58,031 - INFO - [LGSTM] trying {'batch_size': 32, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 13:20:00,423 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 854.87 MiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:20:00,423 - INFO -   score=0.0000
2025-12-19 13:20:00,423 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 13:20:01,356 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 597.38 MiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:20:01,356 - INFO -   score=0.0000
2025-12-19 13:20:01,356 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 13:20:02,348 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 597.70 MiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:20:02,348 - INFO -   score=0.0000
2025-12-19 13:20:02,348 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 13:20:04,306 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.31 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 854.42 MiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:20:04,306 - INFO -   score=0.0000
2025-12-19 13:20:04,306 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 13:20:06,395 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 854.87 MiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:20:06,395 - INFO -   score=0.0000
2025-12-19 13:20:06,395 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 13:20:07,316 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 597.38 MiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:20:07,316 - INFO -   score=0.0000
2025-12-19 13:20:07,316 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 13:20:08,308 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 597.70 MiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:20:08,309 - INFO -   score=0.0000
2025-12-19 13:20:08,309 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 13:20:10,268 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.31 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 854.42 MiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:20:10,268 - INFO -   score=0.0000
2025-12-19 13:20:10,268 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.2, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 13:20:12,361 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 854.87 MiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:20:12,361 - INFO -   score=0.0000
2025-12-19 13:20:12,361 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 13:20:13,295 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 597.38 MiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:20:13,295 - INFO -   score=0.0000
2025-12-19 13:20:13,295 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 13:20:14,288 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 597.70 MiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:20:14,288 - INFO -   score=0.0000
2025-12-19 13:20:14,288 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 13:20:16,246 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.31 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 854.42 MiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:20:16,246 - INFO -   score=0.0000
2025-12-19 13:20:16,246 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 13:20:18,338 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 854.87 MiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:20:18,338 - INFO -   score=0.0000
2025-12-19 13:20:18,338 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'u1': 64, 'u2': 32}
2025-12-19 13:20:19,258 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 597.38 MiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:20:19,258 - INFO -   score=0.0000
2025-12-19 13:20:19,258 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'u1': 64, 'u2': 64}
2025-12-19 13:20:20,250 - INFO -   fit failed: CUDA out of memory. Tried to allocate 5.34 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 597.70 MiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:20:20,250 - INFO -   score=0.0000
2025-12-19 13:20:20,250 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'u1': 128, 'u2': 32}
2025-12-19 13:20:22,209 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.31 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 854.42 MiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:20:22,209 - INFO -   score=0.0000
2025-12-19 13:20:22,209 - INFO - [LGSTM] trying {'batch_size': 64, 'dropout': 0.5, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.0005, 'optimizer': 'adam', 'u1': 128, 'u2': 64}
2025-12-19 13:20:24,301 - INFO -   fit failed: CUDA out of memory. Tried to allocate 10.52 GiB. GPU 0 has a total capacity of 7.50 GiB of which 3.30 GiB is free. Process 1687 has 46.34 MiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 854.87 MiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-19 13:20:24,302 - INFO -   score=0.0000
2025-12-19 13:20:24,302 - INFO - 
✓ Overall Best Model: CNN (score=0.9928)
2025-12-19 13:20:24,302 - INFO -   Best Config: {'batch_size': 32, 'dropout': 0.2, 'f1': 32, 'f2': 128, 'final_activation': 'sigmoid', 'loss': 'binary_crossentropy', 'lr': 0.001, 'optimizer': 'adam'}
2025-12-19 13:20:24,302 - INFO - 
=== FINAL EXPERIMENTS (25, 50, 100 epochs) ===

2025-12-19 13:20:24,302 - INFO - Training CNN for 25 epochs...
2025-12-19 13:20:52,754 - INFO -   Test AUC: 0.9933, F1: 0.2393
2025-12-19 13:20:52,754 - INFO - Training CNN for 50 epochs...
2025-12-19 13:21:49,297 - INFO -   Test AUC: 0.9930, F1: 0.2360
2025-12-19 13:21:49,298 - INFO - Training CNN for 100 epochs...
2025-12-19 13:23:45,644 - INFO -   Test AUC: 0.9931, F1: 0.3141
2025-12-19 13:23:45,644 - INFO - Preparing data for PhysioNet Official Scoring...
2025-12-19 13:23:45,679 - INFO - Scoring on 4035 test patients...
2025-12-19 13:23:45,743 - INFO - 
========================================
2025-12-19 13:23:45,743 - INFO - OFFICIAL PHYSIONET UTILITY SCORE (at 100 epochs)
2025-12-19 13:23:45,743 - INFO - ========================================
2025-12-19 13:23:45,743 - INFO - Model: CNN
2025-12-19 13:23:45,743 - INFO - Normalized Utility Score: 0.0732
2025-12-19 13:23:45,743 - INFO - Raw Utility Score:        235.47
2025-12-19 13:23:45,743 - INFO - ----------------------------------------
2025-12-19 13:23:45,743 - INFO - ========================================
2025-12-19 13:23:45,743 - INFO - 
Generating Plots...
2025-12-19 13:23:45,789 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-12-19 13:23:45,791 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-12-19 13:23:45,895 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-12-19 13:23:45,897 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-12-19 13:23:45,986 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-12-19 13:23:45,988 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
