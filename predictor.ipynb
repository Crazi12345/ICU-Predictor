{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9491a302d73da57c990f2c6e108c8b41",
     "grade": false,
     "grade_id": "cell-0c525bc04cee0423",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1: Data Preparation\n",
    "\n",
    "In this section, we prepare the sepsis prediction dataset from Kaggle: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9e083b9aad949ad0e0440e442270a2f",
     "grade": false,
     "grade_id": "cell-6aa7c9e3c5cb0906",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "86d74ff606f9e0018c827326201b2d26",
     "grade": false,
     "grade_id": "cell-3036e027871562ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's download the entire dataset and save them in the folder named ``data`` on our computer!\n",
    "\n",
    "**Note:** If you have not already installed ``WFDB``, you can do it as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8176bba8a010a79d072beebdbaa5a661",
     "grade": false,
     "grade_id": "cell-77ed09fb4d3c307a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /home/tired_atlas/miniconda3/envs/AI-Health/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging in /home/tired_atlas/miniconda3/envs/AI-Health/lib/python3.11/site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: pyyaml in /home/tired_atlas/miniconda3/envs/AI-Health/lib/python3.11/site-packages (from kagglehub) (6.0.3)\n",
      "Requirement already satisfied: requests in /home/tired_atlas/miniconda3/envs/AI-Health/lib/python3.11/site-packages (from kagglehub) (2.32.5)\n",
      "Requirement already satisfied: tqdm in /home/tired_atlas/miniconda3/envs/AI-Health/lib/python3.11/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/tired_atlas/miniconda3/envs/AI-Health/lib/python3.11/site-packages (from requests->kagglehub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tired_atlas/miniconda3/envs/AI-Health/lib/python3.11/site-packages (from requests->kagglehub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tired_atlas/miniconda3/envs/AI-Health/lib/python3.11/site-packages (from requests->kagglehub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tired_atlas/miniconda3/envs/AI-Health/lib/python3.11/site-packages (from requests->kagglehub) (2025.11.12)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18d18c066d977fd1f9358cdc125b2b95",
     "grade": false,
     "grade_id": "cell-c1561ba8a031cff0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/tired_atlas/.cache/kagglehub/datasets/salikhussaini49/prediction-of-sepsis/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import os\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"salikhussaini49/prediction-of-sepsis\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "092ae2b96a67f0aaadf6e9a6690d9167",
     "grade": false,
     "grade_id": "cell-5cefe4baa9834428",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The sepsis prediction dataset contains patient records in PSV format. Let's explore and load the data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0548bb327063aa8fc206851110227906",
     "grade": false,
     "grade_id": "cell-cca4f183d6a9c631",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 PSV files\n"
     ]
    }
   ],
   "source": [
    "# List available PSV files in the dataset\n",
    "import glob\n",
    "psv_files = glob.glob(os.path.join(path, '*.psv'))\n",
    "print(f\"Found {len(psv_files)} PSV files\")\n",
    "if psv_files:\n",
    "    print(\"Sample files:\", psv_files[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4eda311320a914d8056bc187d74bf697",
     "grade": false,
     "grade_id": "cell-ab300a4d4cd1b244",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We will load the PSV (pipe-separated values) files from the sepsis prediction dataset. These files contain clinical measurements and outcomes for different patients in the ICU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1711560b13b4b18793aaaf6cb2b46c3e",
     "grade": false,
     "grade_id": "cell-1c934c4b74d8e450",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No PSV files found!\n"
     ]
    }
   ],
   "source": [
    "# Load all PSV files and concatenate them\n",
    "df_list = []\n",
    "\n",
    "# Search for PSV files in patient subdirectories\n",
    "for patient_id in patients:\n",
    "    patient_path = os.path.join(path, 'training_setA/training/', patient_id)\n",
    "    if os.path.isdir(patient_path):\n",
    "        # Look for PSV files in each patient directory\n",
    "        for file in os.listdir(patient_path):\n",
    "            if file.endswith('.psv'):\n",
    "                psv_file = os.path.join(patient_path, file)\n",
    "                df_temp = pd.read_csv(psv_file, sep='|')\n",
    "                df_list.append(df_temp)\n",
    "                print(f\"Loaded {os.path.basename(psv_file)}: {df_temp.shape}\")\n",
    "\n",
    "# Combine all dataframes\n",
    "if df_list:\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    print(f\"\\nTotal combined dataset shape: {df.shape}\")\n",
    "    print(f\"\\nColumn names: {df.columns.tolist()}\")\n",
    "else:\n",
    "    print(\"No PSV files found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6af4e870216ce2f339eb0243664116a",
     "grade": false,
     "grade_id": "cell-19fa23ae88546e62",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's explore the dataset and check for missing values and data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe9f0421ceae9aff1e48942caaa1be6e",
     "grade": false,
     "grade_id": "cell-9ac9c9819fed826b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "types\n",
       "N    75052\n",
       "L     8075\n",
       "R     7259\n",
       "V     7130\n",
       "/     7028\n",
       "A     2546\n",
       "+     1291\n",
       "f      982\n",
       "F      803\n",
       "~      616\n",
       "!      472\n",
       "\"      437\n",
       "j      229\n",
       "x      193\n",
       "a      150\n",
       "|      132\n",
       "E      106\n",
       "J       83\n",
       "Q       33\n",
       "e       16\n",
       "[        6\n",
       "]        6\n",
       "S        2\n",
       "Name: val, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0d9f59f5c258fe28390f54fdc23a0ba",
     "grade": false,
     "grade_id": "cell-485b27c14486bd4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's check the target variable and prepare the data for modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae717644f3f1811cb017e3df44954706",
     "grade": false,
     "grade_id": "cell-f105f8745e855b18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Check if there's a sepsis outcome column (usually 'SepsisLabel' or similar)\n",
    "print(\"Value counts for target variable:\")\n",
    "if 'SepsisLabel' in df.columns:\n",
    "    print(df['SepsisLabel'].value_counts())\n",
    "elif 'Outcome' in df.columns:\n",
    "    print(df['Outcome'].value_counts())\n",
    "else:\n",
    "    print(\"Available columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1506959dbba7d9eaf56e334df4cbd197",
     "grade": false,
     "grade_id": "cell-a09dde940c991715",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q1. Please complete the code below to handle missing values and prepare features for the model. You should:\n",
    "1. Remove rows with missing target variable\n",
    "2. Handle missing values in features (either drop or fill)\n",
    "3. Select relevant features for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41ee0011c02a7ce5f80f012c8727f488",
     "grade": false,
     "grade_id": "cell-d62ef81b175d6e7f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "-1     3186\n",
      " 0    75052\n",
      " 1    34409\n",
      "Name: val, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with missing target variable\n",
    "if 'SepsisLabel' in df.columns:\n",
    "    df_clean = df.dropna(subset=['SepsisLabel']).copy()\n",
    "elif 'Outcome' in df.columns:\n",
    "    df_clean = df.dropna(subset=['Outcome']).copy()\n",
    "else:\n",
    "    df_clean = df.copy()\n",
    "\n",
    "print(f\"Dataset shape after removing missing targets: {df_clean.shape}\")\n",
    "\n",
    "# Handle missing values in features - fill with median\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "df_clean[numeric_cols] = df_clean[numeric_cols].fillna(df_clean[numeric_cols].median())\n",
    "\n",
    "print(f\"Missing values after imputation: {df_clean.isnull().sum().sum()}\")\n",
    "print(f\"\\nDataset shape: {df_clean.shape}\")\n",
    "print(df_clean.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5861adce0af1eb0a16ce4a6ba22aa53c",
     "grade": true,
     "grade_id": "cell-406d4d2ebc273f76",
     "locked": true,
     "points": 12,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e9c0bf7f02280d98cfef80040764d33",
     "grade": false,
     "grade_id": "cell-a3429f6fdac5cc55",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Great! We have loaded and cleaned the sepsis prediction dataset. Now it's time to prepare the features and labels for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41f910484d22711a0ab9e1e49718eca9",
     "grade": false,
     "grade_id": "cell-15e714d9060684a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features and target\n",
    "if 'SepsisLabel' in df_clean.columns:\n",
    "    y = df_clean['SepsisLabel'].values\n",
    "    X = df_clean.drop(columns=['SepsisLabel'])\n",
    "elif 'Outcome' in df_clean.columns:\n",
    "    y = df_clean['Outcome'].values\n",
    "    X = df_clean.drop(columns=['Outcome'])\n",
    "else:\n",
    "    print(\"Target column not found. Please check column names.\")\n",
    "    X = df_clean\n",
    "    y = None\n",
    "\n",
    "# Drop non-numeric columns if any\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape if y is not None else 'N/A'}\")\n",
    "print(f\"Target distribution:\\n{pd.Series(y).value_counts()}\")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "print(f\"\\nFeatures after scaling - mean: {X_scaled.mean().mean():.6f}, std: {X_scaled.std().mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f0e1386d5208bc392838c2d48449c54",
     "grade": false,
     "grade_id": "cell-3969edad56c33fd7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's proceed with splitting the data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b17a9c0c4de65cceb785d1ad54705296",
     "grade": false,
     "grade_id": "cell-ba1c074dbfc9f98d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Verify the data is ready for splitting\n",
    "print(\"Data shapes:\")\n",
    "print(f\"X: {X_scaled.shape}\")\n",
    "print(f\"y: {y.shape}\")\n",
    "print(f\"Target class distribution: {pd.Series(y).value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d009ca0cef8e6d4083c54bf123faf112",
     "grade": false,
     "grade_id": "cell-22756420a49ebf28",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's examine the feature distribution and prepare for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e7ed619bbb3f66e222ffcb53f111136",
     "grade": false,
     "grade_id": "cell-11aefddc7f21af99",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ 3\n",
      "J 50\n",
      "N 2700\n",
      "V 3\n",
      "~ 8\n"
     ]
    }
   ],
   "source": [
    "# Display feature statistics\n",
    "print(\"Feature statistics:\")\n",
    "print(f\"Number of features: {X_scaled.shape[1]}\")\n",
    "print(f\"Feature names: {X_scaled.columns.tolist()[:10]}...\")  # Show first 10\n",
    "print(f\"\\nSample features for first row:\")\n",
    "print(X_scaled.iloc[0, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21f72e81b6c7527cb8bb769b527a4483",
     "grade": false,
     "grade_id": "cell-49183c037c641e55",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we're ready to split the data into training and validation sets for model development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb968194ab28899714b691ecb279585b",
     "grade": false,
     "grade_id": "cell-f2a01124c49946d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Great! The data is now prepared and ready for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8aaeec93677d58c1b7d0565fe0eb8636",
     "grade": false,
     "grade_id": "cell-f6892b53ecd05134",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 2: Model Development\n",
    "\n",
    "Let's start the fun part of every machine/deep learning project, model development :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d77f9bd8e83dc03697c5a29d2876b103",
     "grade": false,
     "grade_id": "cell-b7180d2a9e62ecc6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    " Q3. It is the time to split the prepared dataset into train and validation parts. Please complete the code below using ``train_test_split`` function from ``scikit-learn`` library to split the dataset. \n",
    " \n",
    "**Note:** Please set only these two parameters of ``train_test_split`` function and leave the rest as default:\n",
    "\n",
    "``test_size=0.33`` and ``random_state=42``\n",
    "\n",
    "And name the outputs of the function as: ``X_train``, ``X_validation``, ``y_train``, ``y_validation``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "896b0a702cae87a8c2a65577686073e0",
     "grade": false,
     "grade_id": "cell-9441c98451f0267c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (73096, 2160) (36003, 2160) (73096,) (36003,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Remove the initial zero rows that were used for pre-allocation in build_dataset\n",
    "# and split into train/validation sets as requested.\n",
    "X_clean = X[1:,:]\n",
    "Y_clean = Y[1:,:].ravel()\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_clean, Y_clean, test_size=0.33, random_state=42)\n",
    "\n",
    "print('Shapes:', X_train.shape, X_validation.shape, y_train.shape, y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34210df9a03357357336118592e5d81e",
     "grade": true,
     "grade_id": "cell-2feab078a90c54d0",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd319ae773050d58083d8bfc843380ce",
     "grade": false,
     "grade_id": "cell-50c3883d0deab80b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Before we start to develope a CNN and an LSTM model for classify heart arrhytmia, let's have a baseline dense neural networks (with only two dense layers) to compare the results of CNN and LSTM with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a22888f983ecc04a85c12fb620b45d8",
     "grade": false,
     "grade_id": "cell-d696baa2da0c9d3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you have not installed tensorflow already, follow one of the following to install it:\n",
    "\n",
    "1) using simple \"pip\" install:\n",
    "\n",
    "``!pip install tensorflow``\n",
    "\n",
    "2) Open your \"Anaconda Prompt\" and type in the below command to install:\n",
    "\n",
    "``conda install -c conda-forge tensorflow``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83111d0c4d96c06d0743fb91de49cbf0",
     "grade": false,
     "grade_id": "cell-be7561c83e7616ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 14:50:41.625181: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-08 14:50:41.631868: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765201841.640128  134247 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765201841.642849  134247 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1765201841.649569  134247 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765201841.649577  134247 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765201841.649578  134247 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765201841.649579  134247 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-12-08 14:50:41.652044: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/tired_atlas/miniconda3/envs/AI-Health/lib/python3.11/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1765201843.201515  134247 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3238 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5060 Ti, pci bus id: 0000:01:00.0, compute capability: 12.0\n",
      "/home/tired_atlas/miniconda3/envs/AI-Health/lib/python3.11/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1765201843.201515  134247 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3238 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5060 Ti, pci bus id: 0000:01:00.0, compute capability: 12.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1765201845.866410  143404 service.cc:152] XLA service 0x7f8dc4003b20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1765201845.866428  143404 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 5060 Ti, Compute Capability 12.0\n",
      "2025-12-08 14:50:45.893194: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1765201845.985085  143404 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
      "2025-12-08 14:50:46.155278: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155308: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155316: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155321: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155327: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155333: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155339: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155349: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155359: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155368: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155381: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155392: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155504: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.157299: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.157912: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.199650: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.258100: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.258135: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.258151: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.258716: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.262519: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155278: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155308: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155316: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155321: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155327: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155333: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155339: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155349: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155359: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155368: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155381: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155392: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.155504: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.157299: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.157912: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.199650: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.258100: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.258135: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.258151: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.258716: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.262519: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.579491: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.641978: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.579491: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:46.641978: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 181/2285\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 0.7578 - loss: 0.5387"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1765201846.860978  143404 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2253/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.8833 - loss: 0.2983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 14:50:48.957451: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:48.960135: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:48.961145: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:48.961193: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:48.961345: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:48.961483: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:48.961489: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:48.961502: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:48.961542: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:48.961623: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:49.193055: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:49.246949: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:49.193055: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:50:49.246949: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2051\n",
      "Epoch 2/10\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2051\n",
      "Epoch 2/10\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 880us/step - accuracy: 0.9646 - loss: 0.1142\n",
      "Epoch 3/10\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 880us/step - accuracy: 0.9646 - loss: 0.1142\n",
      "Epoch 3/10\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 881us/step - accuracy: 0.9712 - loss: 0.0927\n",
      "Epoch 4/10\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 881us/step - accuracy: 0.9712 - loss: 0.0927\n",
      "Epoch 4/10\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 866us/step - accuracy: 0.9748 - loss: 0.0797\n",
      "Epoch 5/10\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 866us/step - accuracy: 0.9748 - loss: 0.0797\n",
      "Epoch 5/10\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 918us/step - accuracy: 0.9769 - loss: 0.0735\n",
      "Epoch 6/10\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 918us/step - accuracy: 0.9769 - loss: 0.0735\n",
      "Epoch 6/10\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 920us/step - accuracy: 0.9794 - loss: 0.0664\n",
      "Epoch 7/10\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 920us/step - accuracy: 0.9794 - loss: 0.0664\n",
      "Epoch 7/10\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 900us/step - accuracy: 0.9802 - loss: 0.0604\n",
      "Epoch 8/10\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 900us/step - accuracy: 0.9802 - loss: 0.0604\n",
      "Epoch 8/10\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 962us/step - accuracy: 0.9823 - loss: 0.0547\n",
      "Epoch 9/10\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 962us/step - accuracy: 0.9823 - loss: 0.0547\n",
      "Epoch 9/10\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9833 - loss: 0.0518\n",
      "Epoch 10/10\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9833 - loss: 0.0518\n",
      "Epoch 10/10\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9840 - loss: 0.0499\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9840 - loss: 0.0499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f905dd5f190>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow \n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation = 'relu', input_shape = (X_train.shape[1],)))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dropout(rate = 0.2))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size = 32, epochs= 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "831b44564d390d18d895d126fd37da61",
     "grade": false,
     "grade_id": "cell-9f24570e74548165",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's check how well our trained model perform on the validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51d2edc3cbe4da4a8b220101b8345a06",
     "grade": false,
     "grade_id": "cell-ca513bcc3332deb6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 108/1126\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 939us/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 14:51:09.583965: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1110/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 637us/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 14:51:10.454806: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:51:10.457528: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:51:10.464412: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:51:10.474474: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:51:10.502223: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:51:10.502306: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:51:10.506326: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:51:10.510133: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:51:10.510761: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n",
      "2025-12-08 14:51:10.602935: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98     24707\n",
      "         1.0       0.98      0.94      0.96     11296\n",
      "\n",
      "    accuracy                           0.97     36003\n",
      "   macro avg       0.98      0.97      0.97     36003\n",
      "weighted avg       0.97      0.97      0.97     36003\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98     24707\n",
      "         1.0       0.98      0.94      0.96     11296\n",
      "\n",
      "    accuracy                           0.97     36003\n",
      "   macro avg       0.98      0.97      0.97     36003\n",
      "weighted avg       0.97      0.97      0.97     36003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_val = model.predict(X_validation)\n",
    "\n",
    "threshold = 0.5\n",
    "print(classification_report(y_validation, y_pred_val>threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7650648697d10e9a575d23039c30c8f4",
     "grade": false,
     "grade_id": "cell-fdc9db470ce6f994",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q3. Now it is your turn to develop a CNN model. Please complete the cosde below to develope a model architecture as below figure:\n",
    "    \n",
    "<center>\n",
    "<img src=\"fig3.JPG\" width=\"500\"/>  \n",
    "    \n",
    " \n",
    "**Note:** You should set the ``input_shape = (2160, 1)``. This is equal to the length of one heartbeat ($2\\times 3 seconds \\times 360 Hz = 2060 samples$) \n",
    "    \n",
    "**Important:** It may take a while to train the below CNN model on CPU and that is why only 2 epochs is chosen. You may train it on Google Colab on GPU nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44756c91715faa9d8c240c978136a153",
     "grade": false,
     "grade_id": "cell-5f8da70233feda25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Another important step to do here is to reshape the inputs to be ``[num_samples, interval, feature=1]``. You may notice that unlike image datasets that we had ``feature=3`` representing the three channels (RGB), here we have only 1D time series as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "558bef8f58623cf8c5287c5275b915c1",
     "grade": false,
     "grade_id": "cell-beee2323307bef23",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73096, 2160, 1)\n",
      "(36003, 2160, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_reshaped = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_valid_reshaped = np.reshape(X_validation, (X_validation.shape[0], X_validation.shape[1], 1))\n",
    "\n",
    "print(X_train_reshaped.shape)\n",
    "print(X_valid_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d9a4e739a5ac088b827c1118a7304e6",
     "grade": true,
     "grade_id": "cell-a03aa220f67c77d5",
     "locked": false,
     "points": 26,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tired_atlas/miniconda3/envs/AI-Health/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m2283/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9045 - loss: 0.2346"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 14:51:25.849860: W external/local_xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc:1240] Triton does not support sm_120 yet. Passing CC 10.0 to avoid spurious \"unsupported conversion\" errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.1467\n",
      "Epoch 2/2\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.1467\n",
      "Epoch 2/2\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9769 - loss: 0.0707\n",
      "\u001b[1m2285/2285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9769 - loss: 0.0707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f905ddc9850>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "# Simple 1D CNN architecture\n",
    "model.add(Conv1D(filters=32, kernel_size=5, activation='relu', input_shape=(X_train_reshaped.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(X_train_reshaped, y_train, batch_size = 32, epochs= 2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4b16e51e7cde899b0c1e5321245abb1",
     "grade": false,
     "grade_id": "cell-20846b6e310c4dcc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2156</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1078</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1074</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">537</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34368</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,436,900</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2156\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │           \u001b[38;5;34m192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1078\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1074\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m10,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m537\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34368\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │     \u001b[38;5;34m3,436,900\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,342,493</span> (39.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,342,493\u001b[0m (39.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,447,497</span> (13.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,447,497\u001b[0m (13.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,894,996</span> (26.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6,894,996\u001b[0m (26.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc7bbe35b36825548b13fefb346be48f",
     "grade": false,
     "grade_id": "cell-0bde589a294e34b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q4. Please complete the code below to report the performance of the CNN model.\n",
    "\n",
    "**Note:** Please name the model predictions on the validation data (``X_valid_reshaped``) as: ``y_pred_cnn``!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e343c58a611ff0fe72cacde53129d8ea",
     "grade": false,
     "grade_id": "cell-075e2aedfadd94c1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99     24707\n",
      "         1.0       0.98      0.96      0.97     11296\n",
      "\n",
      "    accuracy                           0.98     36003\n",
      "   macro avg       0.98      0.98      0.98     36003\n",
      "weighted avg       0.98      0.98      0.98     36003\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99     24707\n",
      "         1.0       0.98      0.96      0.97     11296\n",
      "\n",
      "    accuracy                           0.98     36003\n",
      "   macro avg       0.98      0.98      0.98     36003\n",
      "weighted avg       0.98      0.98      0.98     36003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict on validation data\n",
    "y_pred_cnn = model.predict(X_valid_reshaped)\n",
    "\n",
    "threshold = 0.5\n",
    "print(classification_report(y_validation, y_pred_cnn>threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dba78fc1f8be94b592a7573dba7c4a42",
     "grade": true,
     "grade_id": "cell-5370e5c986563519",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25467033428ce0529790453e1d72d2e6",
     "grade": false,
     "grade_id": "cell-036b34ff2a7aaa73",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can also plot a Confusion Matrix for our trained classifier on the validation data! You should use ``confusion_matrix`` method/function from scikit-learn library for this purpose. For more help and see some examples on how to use``confusion_matrix``, please read here: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html  \n",
    "\n",
    "Q5. Please complete the code below for calculating the confusion matrix for the validation data and name it ``cm``.\n",
    "\n",
    "**Hint:** The confusion matrix sould look like the below:\n",
    "\n",
    "<center>\n",
    "<img src=\"fig5.JPG\" width=\"400\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "321cda99a84d8778836cf48ec9118855",
     "grade": false,
     "grade_id": "cell-85e8c31f898f0247",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute confusion matrix for CNN predictions\n",
    "y_pred_labels = (y_pred_cnn > 0.5).ravel()\n",
    "cm = confusion_matrix(y_validation, y_pred_labels)\n",
    "# Normalize the confusion matrix by row (true labels)\n",
    "cm = cm.astype(float)\n",
    "cm = cm / cm.sum(axis=1)[:, None]\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(cm, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0398633859f6234b793bd2474d6a141",
     "grade": true,
     "grade_id": "cell-e609f962a9cbdb31",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bed21e5692ebaac6e846eb9e8e3961e1",
     "grade": false,
     "grade_id": "cell-304e70d0353e6080",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q6. Now it is time to develop an LSTM model. Please complete the cosde below to develope a model architecture as below figure:\n",
    "    \n",
    "<center>\n",
    "<img src=\"fig4.JPG\" width=\"500\"/>  \n",
    "    \n",
    " \n",
    "**Note 1:** You should set the ``input_shape = (X_train_reshaped.shape[1], X_train_reshaped.shape[2])``. These are equal to the number of samples (heartbeats) and length of one heartbeat ($2\\times 3 seconds \\times 360 Hz = 2060 samples$). \n",
    "    \n",
    "**Note 2:** The ``return_sequences=True`` force the LSTM/BiLSTM layer to return the output for each LSTM cell/unit.    \n",
    "    \n",
    "**Important:** It may take a while to train the below LSTM model on CPU and that is why only 2 epochs is chosen. You may train it on Google Colab on GPU nodes. Here, we reduce the size of the dataset (``X_train_cnn[:10000], y_train[:10000]``) to make it feasible for quick prototyping but you should train the model with the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f912aa3b67c5db6efdfc30dc23af291d",
     "grade": true,
     "grade_id": "cell-7a62bbec909ad85e",
     "locked": false,
     "points": 26,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tired_atlas/miniconda3/envs/AI-Health/lib/python3.11/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 203ms/step - accuracy: 0.6885 - loss: 0.6202\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 203ms/step - accuracy: 0.6885 - loss: 0.6202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f8e28265bd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "\n",
    "model_lstm = Sequential()\n",
    "# Bidirectional stacked LSTM architecture\n",
    "model_lstm.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model_lstm.add(Bidirectional(LSTM(32)))\n",
    "model_lstm.add(Dense(64, activation='relu'))\n",
    "model_lstm.add(Dropout(0.5))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_lstm.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model_lstm.fit(X_train_reshaped[:10000], y_train[:10000], batch_size = 32, epochs= 1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df8505a9b005e46fc2b3e4310bded0da",
     "grade": false,
     "grade_id": "cell-fcdeb583aed5f12b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2160\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m33,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m41,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">237,701</span> (928.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m237,701\u001b[0m (928.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,233</span> (309.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,233\u001b[0m (309.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">158,468</span> (619.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m158,468\u001b[0m (619.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "140f0131cf508c6c29f8b1f405636372",
     "grade": false,
     "grade_id": "cell-f5333e4963860835",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Q7. Please complete the code below to report the performance of the LSTM model.\n",
    "\n",
    "**Note:** Please name the model predictions on the validation data (``X_valid_reshaped``) as: ``y_pred_lstm``!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67058e34486aa0f8bd3ff7ed7d61737f",
     "grade": false,
     "grade_id": "cell-d033bf9d65ba1aef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 97ms/step\n",
      "\u001b[1m1126/1126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 97ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.98      0.82     24707\n",
      "         1.0       0.63      0.06      0.11     11296\n",
      "\n",
      "    accuracy                           0.69     36003\n",
      "   macro avg       0.66      0.52      0.46     36003\n",
      "weighted avg       0.67      0.69      0.59     36003\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.98      0.82     24707\n",
      "         1.0       0.63      0.06      0.11     11296\n",
      "\n",
      "    accuracy                           0.69     36003\n",
      "   macro avg       0.66      0.52      0.46     36003\n",
      "weighted avg       0.67      0.69      0.59     36003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict with the trained LSTM model\n",
    "y_pred_lstm = model_lstm.predict(X_valid_reshaped)\n",
    "\n",
    "threshold = 0.5\n",
    "print(classification_report(y_validation, y_pred_lstm>threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "737498b8e44acd6a2cd1edb25f349666",
     "grade": true,
     "grade_id": "cell-7a3ceb071c10868c",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ddfff79a80b0b6c30e42920ae3393820",
     "grade": false,
     "grade_id": "cell-a84223285ef3344d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Next Steps\n",
    "\n",
    "Well done! You have learnt how to develop CNN and LSTM models on real-world time series datasets. But, what can be done to improve our model?\n",
    "\n",
    "\n",
    "* There are some parameters in the CNN and LSTM models that can be optimized such as:\n",
    "        1. number of filters in the CNN model.\n",
    "        2. number of layers in the LSTM model. \n",
    "\n",
    "\n",
    "* The model architectures such as number of layers can be explored further to improve the performance.\n",
    "\n",
    "\n",
    "* We can develop a new model by combining CNN and LSTM layers.\n",
    "\n",
    "\n",
    "* We can use a completely unseen dataset to test our trained model. For this purpose, two datasets can be used:\n",
    "        1.MIT-BIH Supraventricular Arrhythmia Database (https://physionet.org/content/svdb/1.0.0/)\n",
    "        2. St Petersburg INCART 12-lead Arrhythmia Database (https://physionet.org/content/incartdb/1.0.0/)  \n",
    "        \n",
    "        \n",
    "##### So, if you are interested in learning more about time series classification using ECG signals and doing your final report (and/or perhaps your Master thesis) on this topic, please contact me :)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da646d13c56e03148eb0a1becee49368",
     "grade": false,
     "grade_id": "cell-c8d3d03a0f06085d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Thank you!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "AI-Health",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
